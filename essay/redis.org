* redis
#+OPTIONS: H:4
   - alphazero/jredis · GitHub https://github.com/alphazero/jredis Java Client 支持异步操作 *NOTE（dirlt）：实际不支持*     

** 简介
主页是http://redis.io/. redis(REmote DIctionary Server)是kv数据库，对于k来说的话允许是binary,而对于v来说的话可以支持很多数据结构。
作者的主页是http://antirez.com/, http://invece.org/. github是https://github.com/antirez/. 推荐这些的原因主要是因为作者真的是非常非常强的人。
redis的代码在2w左右，但是包含的内容非常多包括精巧的数据结构设计，主从同步，虚拟内存控制，网络服务，事务支持等等。代码使用C进行开发，
基本上没有任何封装，作者所写的代码都是用来直接解决具体问题的。针对redis从下面几个方面入手：
   - data-type.数据结构
   - command.命令
   - virtual-memory.虚拟内存
   - disk-storage.磁盘存储
   - network-server.网络服务
   - high-availability.HA
了解了上面几个方面的知识之后看代码的话会比较方便(至少是有头绪).通过如果大家想尝试redis的话甚至可以不用搭建redis server,
这里有个website可以尝试在线使用http://try.redis-db.com/. 界面和交互效果非常漂亮。另外这里有一些参考资源的汇总http://blog.nosqlfan.com/html/3537.html.
不过我觉得redis本身就不是非常复杂，所以阅读文档足够了解其功能以及大致的内部实现。

NOTE(dirlt):redis可能是单CPU线程程序。之所以猜测这点主要是从事务以及scripting(完成事务)的实现考虑的。如果scripting需要完成事务的话，
外围是没有办法来进行log的。但是又需要保证scripting是原子操作完成的话，那么只能够是单CPU线程来实现。不过好像之前也记得同学提到过这个问题，
对于并发的话redis是通过进程来完成的。不过其实这非常现实，多线程来操作对象让每个对象上面都带上一把mutex的话，无疑会让代码更加混乱。bravo,antirez.

** 数据结构
相关资源：
   - Data types. http://redis.io/topics/data-types
   - A fifteen minute introduction to Redis data types. http://redis.io/topics/data-types-intro

redis本身是kv数据库，k来说的话支持string(not c-style string.可以支持binary).而对于v来说的话支持下面几种数据结构：
   - string.上限521M，可以从来当做bitmap使用。但是命令上支持整数操作比如INCR只要string内容本身可以被解析为整数。
   - list.提供的接口和linked-list类似，不支持遍历也没有索引，对于value只允许是string.可以push/pop/slice.
   - hash.对于kv也都必须是string，不支持遍历。
   - set.对于value只允许是string.命令上支持集合之间的并交叉运算(union/intersect/diff).
   - sorted-set.和set差不多但是对于每个value来说还有一个float number的attribute(score).这样对于value来说可以进行排序，同时针对score进行范围查询。
对于每种数据结构，redis仅仅是规定其语义但是内部实现的话却非常灵活，因为redis为了尽可能地将内容存放到内存中，针对这些数据结构实现做了内存大小优化(同时在性能上不会牺牲很多).
这里有必要提一下sorted-set实现，将score放在skip-list里面，将value放在hashtable里面。这样可以针对value进行去重和查找，同时可以针对score进行范围查询和扫描。

** 命令
Commands. http://redis.io/commands official very comprehensive.

命令包括下面几个部分：
   - key的操作
   - 数据结构操作
   - pub/sub
   - transaction
   - scripting
   - connection
   - server

*** key
   - DEL key. 删除key.
   - KEYS pattern. 返回匹配pattern的所有key.
   - PEXPIRE key millseconds. 设置key的毫秒超时时间。
   - RENAMENX key newkey. 重命名key为newkey如果newkey不存在的话。这里NX(Not eXist).
   - DUMP key. 返回key所对应的object二进制表示
   - MIGRATE host port key dest-db timeout. 迁移key到另外机器的db上。
   - PEXPIREAT key millseconds-timestamp. 设置key的毫秒超时时间点。
   - RESTORE key ttl serialized-value. 其中serialized-value为DUMP产生的内容，来恢复/创建key并且设置超时时间。
   - EXISTS key. key是否存在
   - MOVE key db. 将key移到db
   - PTTL key. key剩余存活时间(in millseconds).
   - SORT key [...]. key对应的value只允许是list,set和sorted-set，针对value按照不同策略进行排序。
   - EXPIRE key. 设置key的秒级超时时间。
   - OBJECT subcommand [...] 查看key对应object的meta信息。
   - RANDOMKEY 从keyspace返回一个随机key.
   - TTL key. key剩余存活时间(in seconds).
   - EXPIREAT key timestamp. 设置key的秒级超时时间点。
   - PERSIST key. 取消key超时。
   - RENAME key newkey. 重命名key为newkey.
   - TYPE key. key对应object的类型。

我们这里稍微看看超时命令的实现机制。http://redis.io/commands/expire. 实现上是一个概率算法，
每隔100ms会扫描可能出现expire key的keyspace，选择其中100个出来进行检查，如果出现25个以上expire的话
那么进行重新检查否则停止等待100ms之后下一轮检查。expire内部实现是按照unix timestamp来存储的，
所以dump rdb是没有关系的。对应replication以及AOF应对expire的话，不管对于replication还是AOF
本身并不会执行expire算法，而是等待master节点发出一个DEL并且确认返回(否则非常容易出现状态不一致).

*** data-type
关于数据类型方面的命令这里不打算详细分析，因为了解数据类型之后很多提供的命令都可以猜到了。

*** pub/sub
Pub/Sub. http://redis.io/topics/pubsub.

redis提供了pub/sub机制可以使得应用很方便地做message queue工作。但是这种message queue是种在线方式的message queue.
如果subscribe在publish之后发起的话那么会丢掉数据。如果希望工作方式是离线的话，可以使用list来模拟message queue.
我猜想resque(http://rubygems.org/gems/resque)应该是用离线方式工作的。
   - PSUBSCRIBE pattern [pattern...] 订阅某些pattern(匹配channel)的信息
   - PUNSUBSCRIBE [pattern...] 取消某些pattern(匹配channel)的订阅
   - UNSUBSCRIBE channel [channel...] 取消订阅某些channel.
   - PUBLISH channel message 向channel发布消息
   - SUBSCRIBE channel [channel...] 订阅某些channel.

*** transaction
Transaction. http://redis.io/topics/transactions.

关于transaction主要是为了解决在client端发起多个操作的需求，而redis scripting功能现在也能够满足transaction功能并且实现得更加优雅。
用户可以通过向redis提交lua script到服务器端进行原子计算(如果是这样推断的话，那么可能redis是单CPU线程程序，通过进程来增加并发).
感觉redis的transaction设计得恰到好处，在实现简单和功能足够的之间达到了折衷。
   - DISCARD. 放弃事务。
   - MULTI. 发起事务。
   - WATCH key [key..]. 监控键值，通常在发起事务之前执行。WATCH机制的引入主要就是为了提供类似于CAS(check-and-set)语义，这个在文档里面介绍得很清楚。
   - EXEC. 执行之前发起的事务。
   - UNWATCH. 删除所有的监控键值。

*** scripting
Scripting. http://redis.io/commands/eval.

有了scripting可以通过提交lua script到redis server上面然后在服务端进行计算。同时redis保证只有一个lua interpreter在执行lua script所以可以实现事务功能。
script可以在redis server进行缓存，用户也可以强制server将script全部删除掉。对于cache住的script,用户可以通过这个script的SHA1来访问。
   - EVAL script numkeys key [key ...] arg [arg ...]. 执行script并且这个script会在server缓存。
   - EVALSHA sha1 numkeys key [key ...] arg [arg ...]. 这个和EVAL一样，但是可以通过sha1来调用已经缓存住的script.
   - SCRIPT FLUSH. 移除所有的script cache.
   - SCRIPT LOAD script. 将script放到server端进行cache但是不执行。
   - SCRIPT EXISTS scriptc [script...] 检查多个sha1 script是否存在。
   - SCRIPT KILL. 终止当前执行的script.

*** connection
   - AUTH password. 进行身份验证。
   - PING. 对server进行ping操作。
   - SELECT index. 其中index为数字，默认为0.使用DB index.
   - ECHO message. server做echo服务。
   - QUIT. 断开连接。断开连接之后server会将所有的pending replies都返回给client.

*** server
   - BGREWRITEAOF. background重写AOF，这样可以缩小日志部分。关于AOF会在磁盘存储部分说明。
   - DBSIZE. number of keys.
   - INFO. information about server.
   - SLAVEOF host port. 这台redis-server作为host/port的slave.SLAVEOF NO ONE可以让这台机器变成master.
   - BGSAVE. background进行dump保存为dump.rdb.
   - DEBUG OBJECT key. TODO(dirlt):
   - LASTSAVE. 最后完成SAVE的unix timestamp.
   - SLOWLOG subcommand [argument]. 关于慢日志的控制和查询。
   - CONFIG GET parameter. 获取redis参数配置。
   - DEBUG SEGFAULT. 让redis server主动crash(SIGSEGV).
   - MONITOR. 监控到所有发送给redis server的command.通常是telnet登陆上去然后执行monitor来进行观察。
   - SYNC. 触发sync操作让slave和master进行同步。
   - CONFIG SET parameter value. 对redis进行参数配置。
   - FLUASHALL. 从所有db中删除所有的key.
   - SAVE. 前台进行dump保存为dump.rdb.
   - TIME. 当前server的unix timestamp.
   - CONFIG RESETSTAT. 重新按照INFO的配置来进行设置。(这里可以猜想INFO配置应该从配置文件来的，而没有包含动态配置修改).
   - FLUSHDB. 从当前db中删除所有的key.
   - SHUTDOWN [NOSAVE] [SAVE]. 关闭redis sever，之前可选地会进行SAVE并且flush AOF，同时断开所有的客户端连接。

** 虚拟内存
相关资源：
   - Virtual Memory technical specification. http://redis.io/topics/internals-vm
   - Memory Optimization. http://redis.io/topics/memory-optimization

关于虚拟内存，redis网站的文档讲解得是非常的详细，而且似乎为了这个功能的实现作者应该也下来不少功夫。首先redis是一个kv数据库，
但是对于底层存储的话kv都表示成为redisObject存在，但是key永远不会swap出去只会将value swap出去。swap实现方面也借鉴了OS，
按照page进行swap.redis-server允许配置page size以及swap page number.对于触发swap条件是在主线程定期会判断当前占用内存大小，
如果占用内存过多的话，那么会开始将部分redisObject swap到disk上面去直到满足条件。对于这个object会扫描整个keyspace，权重按照下面公式
#+BEGIN_SRC C++
swappability = age*log(size_in_memory)
#+END_SRC
其中age是距离上次访问的时间，size_in_memory是一种快速计算占用内存大小的估值。每个换出的对象都会计算出序列化成为.rdb格式的大小，
实现上还是非常有意思的，实际上并没有真实地进行序列化，而是将其序列化到/dev/null文件里面然后ftell看看大小多少。得到object rdb size
之后就可以计算占用的page number.redis-server找出连续page number的文件空间，然后将这个object swap到这些块上面。至于这个swap block的
管理是通过bitmap来完成的。

对于redis来说包含两种VM机制，blocking和threaded vm.其实关系非常简单，threaded vm就是通过增加io thread然后在thread里面执行blocking vm.
文档里面作者提到了当时考虑解决blocking vm的问题，包含三种方式：
   - 将redis修改成为multi-thread工作方式。
   - 将swap io部分修改成为nonblocking方式，和io thread工作方式一样只不过这个thread是kernel thread.
   - io thread但是线程是userspace thread.这也是redis采用的方式。

threaded vm还有两个需要注意的地方。1)就是redis针对操作必须首先判断这个操作所涉及的所有的keys是否都已经在memory了，如果有一个key
依然是被swap的话，那么需要首先block这个请求，将这个请求里面放到io thread里面先将所有的key全部swap出来。但是与此同时必须防止swap线程
与此同时将这些key swap出去，所以可以先做一个标记/或者是lock方式swap out线程工作。2)一旦swap in之后的话那么通过pipe方式通知CPU线程所有
的key都已经load into memory.

There are basically three main ways to turn the blocking VM into a non blocking one. - 1: One way is obvious, and in my opionion, not a good idea at all, that is, turning Redis itself into a theaded server: if every request is served by a different thread automatically other clients don't need to wait for blocked ones. Redis is fast, exports atomic operations, has no locks, and is just 10k lines of code, because it is single threaded, so this was not an option for me. - 2: Using non-blocking I/O against the swap file. After all you can think Redis already event-loop based, why don't just handle disk I/O in a non-blocking fashion? I also discarded this possiblity because of two main reasons. One is that non blocking file operations, unlike sockets, are an incompatibility nightmare. It's not just like calling select, you need to use OS-specific things. The other problem is that the I/O is just one part of the time consumed to handle VM, another big part is the CPU used in order to encode/decode data to/from the swap file. This is I picked option three, that is... - 3: Using I/O threads, that is, a pool of threads handling the swap I/O operations. This is what the Redis VM is using, so let's detail how this works.

在进行磁盘存储比如BGSAVE或者是BGREWRITEAOF的时候，child process会得到一个parent process的内存镜像。但是注意这个内存镜像里面的一些
value可能还在swap file上面，child process需要将这些value swap in.但是如果这个时候parent process的swap out线程依然在工作的话，
那么相当于出现同时操作swap file.所以在进行BGSAVE或者是BGREWRITEAOF的时候会将parent process的swap out工作停止。

** 磁盘存储
相关资源：
   - Persistence. http://redis.io/topics/persistence
   - Redis-RDB-Dump-File-Format. https://github.com/sripathikrishnan/redis-rdb-tools/wiki/Redis-RDB-Dump-File-Format
   - Redis或弃用当前VM机制，采用新的diskstore模型. http://blog.nosqlfan.com/html/1047.html
   - Redis新的存储模式diskstore. http://timyang.net/data/redis-diskstore/
   - Redis persistence demystified. http://antirez.com/post/redis-persistence-demystified.html

当前redis磁盘存储方式有两种，一种是RDB(redis db)，一种是AOF(append-only file).可以看到磁盘存储上redis并没有非常方便的查找结构，
这也和redis的初始定位有关，redis一开始定位就是内存kv数据库。

RDB相当于redis的一个checkpoint,但是存储格式是二进制。工作方式非常简单，就是当需要BGSAVE/SAVE的时候(如果是BGSAVE的话那么会fork进程出来),
然后将redis server里面所有的对象都dump成为dump.rdb文件。优势非常明显，二进制文件占用空间很少，并且只有一个文件非常容易恢复，并且磁盘
操作相对较少只有当需要SAVE时候才有(子进程dump时候父进程不会fork新的进程)，但是劣势也很明显。因为dump是整个server的数据，所以非常耗时，
那么这段时间数据如果是写内存的话如果server crash的话，那么会有数据丢失。同时fork可能也非常耗时(linux下面实现是COW方式,所以时间相对还好).

AOF则类似于redo-log的工作方式，所有对于server数据的修改都会作为log记录下来，然后有几个策略来进行刷新. 1)每次写log都会进行fsync.
2)每秒都会将收集的log进行fsync. 3)不调用fsync让OS操作。不同的策略在crash情况下面会造成不同比率数据的丢失，作者推荐使用2方法。
AOF都会写到appendonly.aof文件里面，我们可以看看一个aof的example.很显然这是一个human-readable的格式(但是我没有兴趣分析其格式).
#+BEGIN_EXAMPLE
dirlt@dirlt-virtual-machine:~/utils/redis/bin$ cat appendonly.aof
*2
$6
SELECT
$1
0
*3
$5
RPUSH
$1
c
$1
e
#+END_EXAMPLE
如果system crash的话，那么我们可以拿这个AOF进行恢复。相比RDB的方式因为使用的是文本表示所以占用空间大很多，同时恢复时间因为是redo所以相对较长。

另外需要注意的一个问题是就是如果存在删除操作或者是INCR这样的update-inplace的操作的话，AOF很快就会变大。redis提供了压缩AOF的方式(从命令上来看是需要进行手动触发).压缩原理很简单，
就是保存最后的值但是依然是以AOF格式来保存的。AOF工作原理和RDB非常类似，首先fork子进程出来，然后再child process里面去产生新的AOF文件，成功之后parent process
将这段时间的AOF全部追加到新的AOF文件里面，然后将原来的AOF文件删除进行切换。

** 网络服务
相关资源：
   - Event Library. http://redis.io/topics/internals-eventlib 对于event library的理解不过都是一些基本的问题。
   - Redis Event Library. http://redis.io/topics/internals-rediseventlib redis的event library的实现。
   - Pipelining. http://redis.io/topics/pipelining 通过pipelining的方式隐藏网络带来的延迟。其实就是批量处理方式。
   - Protocol specification. http://redis.io/topics/protocol protocol规范，可以看得出格式上还是非常human-readable的。
关于网络服务不打算详细分析。

** HA方案
相关资源：
   - Replication. http://redis.io/topics/replication
   - Redis Cluster. http://redis.io/presentation/Redis_Cluster.pdf

现在redis的replication方式只有master/slave方案(one master and serveral slaves).slave可以进行级联但是不允许作为多个master的slave.
(这个在SLAVEOF命令里面有说明，如果原来已经是slave如果使用SLAVEOF的话，那么就不会follow原来的master而会follow新的master,同时将原来
的数据全部discard).replication不会阻塞master也不会阻塞slave,对于master的更新都会通过异步数据的方式传递给slave节点。master如果检测到
有多个slave连接上来的话(SYNC)，那么首先会做background saving然后将rdb文件传送给所有的slave,并且将这段时间的commands也传给slave.
(可以通过telnet/SYNC来查看传输结果，同时也可以看到master会隔断时间发送PING来做心跳检测).

** sentinel
http://redis.io/topics/sentinel

sentinel功能是为了解决redis在分布式使用场景中主从automatic failover的情况， 包括下面这几个功能：
   - Monitoring. Sentinel constantly check if your master and slave instances are working as expected.（监控redis node是否正常工作）
   - Notification. Sentinel can notify the system administrator, or another computer program, via an API, that something is wrong with one of the monitored Redis instances.（如果node没有正常工作那么可以通知）
   - Automatic failover. If a master is not working as expected, Sentinel can start a failover process where a slave is promoted to master, the other additional slaves are reconfigured to use the new master, and the applications using the Redis server informed about the new address to use when connecting.（如果master节点没有正常工作的话，可以选择启动新的slave来作为master，完成故障的自动恢复。自己实现了一个agreement protocol来完成选主）

TODO（dirlt)：考虑到redis的代码质量比较高，对于redis的automatic failover实现机制可以好好分析并且阅读代码。

** 代码分析
TODO(dirlt):
   - aof.c
   - db.c
   - config.c
   - multi.c
   - networking.c
   - object.c
   - pubsub.c
   - rdb.c
   - redis-*.c
   - replication.c
   - slowlog.c
   - sort.c
   - t_*.c
   - vm.c

*** Common
redis将大部分的结构，常量以及API都放在redis.h头文件里面。内容非常多但是每个部分非常清晰。
这里仅仅是列出常量定义以及涉及到独立结构和API。和具体功能相关的结构以及API的话会单独分节分析。

**** defines
非常多的常量。个人觉得倒是没有必要仔细阅读，结合代码流程来看各个变量的意义会更有价值。
#+BEGIN_SRC C++
/* Error codes */
#define REDIS_OK                0
#define REDIS_ERR               -1

/* Static server configuration */
// 服务器配置默认参数
#define REDIS_SERVERPORT        6379    /* TCP port */ // 默认tcp server端口
#define REDIS_MAXIDLETIME       0       /* default client timeout: infinite */
#define REDIS_MAX_QUERYBUF_LEN  (1024*1024*1024) /* 1GB max query buffer. */
#define REDIS_IOBUF_LEN         (1024*16)
#define REDIS_LOADBUF_LEN       1024
#define REDIS_DEFAULT_DBNUM     16
#define REDIS_CONFIGLINE_MAX    1024
#define REDIS_MAX_SYNC_TIME     60      /* Slave can't take more to sync */
#define REDIS_EXPIRELOOKUPS_PER_CRON    10 /* lookup 10 expires per loop */
#define REDIS_MAX_WRITE_PER_EVENT (1024*64)
#define REDIS_REQUEST_MAX_SIZE (1024*1024*256) /* max bytes in inline command */
#define REDIS_SHARED_SELECT_CMDS 10
#define REDIS_SHARED_INTEGERS 10000
#define REDIS_REPLY_CHUNK_BYTES (5*1500) /* 5 TCP packets with default MTU */
#define REDIS_INLINE_MAX_SIZE   (1024*64) /* Max size of inline reads */
#define REDIS_MAX_LOGMSG_LEN    4096 /* Default maximum length of syslog messages */ // syslog日志最大长度
#define REDIS_AUTO_AOFREWRITE_PERC  100
#define REDIS_AUTO_AOFREWRITE_MIN_SIZE (1024*1024)
#define REDIS_SLOWLOG_LOG_SLOWER_THAN 10000
#define REDIS_SLOWLOG_MAX_LEN 64

// replication配置.
#define REDIS_REPL_TIMEOUT 60
#define REDIS_REPL_PING_SLAVE_PERIOD 10

/* Hash table parameters */
// 数据结构hashtable参数
#define REDIS_HT_MINFILL        10      /* Minimal hash table fill 10% */

/* Command flags:
 *   REDIS_CMD_DENYOOM:
 *     Commands marked with this flag will return an error when 'maxmemory' is
 *     set and the server is using more than 'maxmemory' bytes of memory.
 *     In short: commands with this flag are denied on low memory conditions.
 *   REDIS_CMD_FORCE_REPLICATION:
 *     Force replication even if dirty is 0. */
#define REDIS_CMD_DENYOOM 4 // 如果出现OOM的话那么直接返回错误.
#define REDIS_CMD_FORCE_REPLICATION 8

/* Object types */
#define REDIS_STRING 0
#define REDIS_LIST 1
#define REDIS_SET 2
#define REDIS_ZSET 3
#define REDIS_HASH 4
#define REDIS_VMPOINTER 8

/* Object types only used for persistence in .rdb files */
#define REDIS_HASH_ZIPMAP 9
#define REDIS_LIST_ZIPLIST 10
#define REDIS_SET_INTSET 11
#define REDIS_ZSET_ZIPLIST 12

/* Objects encoding. Some kind of objects like Strings and Hashes can be
 * internally represented in multiple ways. The 'encoding' field of the object
 * is set to one of this fields for this object. */
#define REDIS_ENCODING_RAW 0     /* Raw representation */
#define REDIS_ENCODING_INT 1     /* Encoded as integer */
#define REDIS_ENCODING_HT 2      /* Encoded as hash table */
#define REDIS_ENCODING_ZIPMAP 3  /* Encoded as zipmap */
#define REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */
#define REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist */
#define REDIS_ENCODING_INTSET 6  /* Encoded as intset */
#define REDIS_ENCODING_SKIPLIST 7  /* Encoded as skiplist */

/* Object types only used for dumping to disk */
#define REDIS_EXPIRETIME 253
#define REDIS_SELECTDB 254
#define REDIS_EOF 255

/* Defines related to the dump file format. To store 32 bits lengths for short
 * keys requires a lot of space, so we check the most significant 2 bits of
 * the first byte to interpreter the length:
 *
 * 00|000000 => if the two MSB are 00 the len is the 6 bits of this byte
 * 01|000000 00000000 =>  01, the len is 14 byes, 6 bits + 8 bits of next byte
 * 10|000000 [32 bit integer] => if it's 01, a full 32 bit len will follow
 * 11|000000 this means: specially encoded object will follow. The six bits
 *           number specify the kind of object that follows.
 *           See the REDIS_RDB_ENC_* defines.
 *
 * Lenghts up to 63 are stored using a single byte, most DB keys, and may
 * values, will fit inside. */
#define REDIS_RDB_6BITLEN 0
#define REDIS_RDB_14BITLEN 1
#define REDIS_RDB_32BITLEN 2
#define REDIS_RDB_ENCVAL 3
#define REDIS_RDB_LENERR UINT_MAX

/* When a length of a string object stored on disk has the first two bits
 * set, the remaining two bits specify a special encoding for the object
 * accordingly to the following defines: */
#define REDIS_RDB_ENC_INT8 0        /* 8 bit signed integer */
#define REDIS_RDB_ENC_INT16 1       /* 16 bit signed integer */
#define REDIS_RDB_ENC_INT32 2       /* 32 bit signed integer */
#define REDIS_RDB_ENC_LZF 3         /* string compressed with FASTLZ */

// 客户端标记.
/* Client flags */
#define REDIS_SLAVE 1       /* This client is a slave server */
#define REDIS_MASTER 2      /* This client is a master server */
#define REDIS_MONITOR 4     /* This client is a slave monitor, see MONITOR */
#define REDIS_MULTI 8       /* This client is in a MULTI context */
#define REDIS_BLOCKED 16    /* The client is waiting in a blocking operation */
#define REDIS_IO_WAIT 32    /* The client is waiting for Virtual Memory I/O */
#define REDIS_DIRTY_CAS 64  /* Watched keys modified. EXEC will fail. */
#define REDIS_CLOSE_AFTER_REPLY 128 /* Close after writing entire reply. */
#define REDIS_UNBLOCKED 256 /* This client was unblocked and is stored in
                               server.unblocked_clients */

/* Client request types */
#define REDIS_REQ_INLINE 1
#define REDIS_REQ_MULTIBULK 2

/* Slave replication state - slave side */
#define REDIS_REPL_NONE 0 /* No active replication */
#define REDIS_REPL_CONNECT 1 /* Must connect to master */
#define REDIS_REPL_CONNECTING 2 /* Connecting to master */
#define REDIS_REPL_TRANSFER 3 /* Receiving .rdb from master */
#define REDIS_REPL_CONNECTED 4 /* Connected to master */

/* Synchronous read timeout - slave side */
#define REDIS_REPL_SYNCIO_TIMEOUT 5

/* Slave replication state - from the point of view of master
 * Note that in SEND_BULK and ONLINE state the slave receives new updates
 * in its output queue. In the WAIT_BGSAVE state instead the server is waiting
 * to start the next background saving in order to send updates to it. */
#define REDIS_REPL_WAIT_BGSAVE_START 3 /* master waits bgsave to start feeding it */
#define REDIS_REPL_WAIT_BGSAVE_END 4 /* master waits bgsave to start bulk DB transmission */
#define REDIS_REPL_SEND_BULK 5 /* master is sending the bulk DB */
#define REDIS_REPL_ONLINE 6 /* bulk DB already transmitted, receive updates */

/* List related stuff */
#define REDIS_HEAD 0
#define REDIS_TAIL 1

/* Sort operations */
#define REDIS_SORT_GET 0
#define REDIS_SORT_ASC 1
#define REDIS_SORT_DESC 2
#define REDIS_SORTKEY_MAX 1024

/* Anti-warning macro... */
#define REDIS_NOTUSED(V) ((void) V)

#define ZSKIPLIST_MAXLEVEL 32 /* Should be enough for 2^32 elements */
#define ZSKIPLIST_P 0.25      /* Skiplist P = 1/4 */

/* Zip structure related defaults */
#define REDIS_HASH_MAX_ZIPMAP_ENTRIES 512
#define REDIS_HASH_MAX_ZIPMAP_VALUE 64
#define REDIS_LIST_MAX_ZIPLIST_ENTRIES 512
#define REDIS_LIST_MAX_ZIPLIST_VALUE 64
#define REDIS_SET_MAX_INTSET_ENTRIES 512
#define REDIS_ZSET_MAX_ZIPLIST_ENTRIES 128
#define REDIS_ZSET_MAX_ZIPLIST_VALUE 64

/* Sets operations codes */
#define REDIS_OP_UNION 0
#define REDIS_OP_DIFF 1
#define REDIS_OP_INTER 2

/* Redis maxmemory strategies */
#define REDIS_MAXMEMORY_VOLATILE_LRU 0
#define REDIS_MAXMEMORY_VOLATILE_TTL 1
#define REDIS_MAXMEMORY_VOLATILE_RANDOM 2
#define REDIS_MAXMEMORY_ALLKEYS_LRU 3
#define REDIS_MAXMEMORY_ALLKEYS_RANDOM 4
#define REDIS_MAXMEMORY_NO_EVICTION 5
#+END_SRC

**** structs
***** redisServer
redis作为Server的结构，使用上应该是全局变量。
#+BEGIN_SRC C++
/* Global server state structure */
struct redisServer {
    pthread_t mainthread;
    int arch_bits;
    int port;
    char *bindaddr;
    char *unixsocket;
    mode_t unixsocketperm;
    int ipfd;
    int sofd;
    redisDb *db;
    long long dirty;            /* changes to DB from the last save */
    long long dirty_before_bgsave; /* used to restore dirty on failed BGSAVE */
    list *clients;
    dict *commands;             /* Command table hahs table */
    /* RDB / AOF loading information */
    int loading;
    off_t loading_total_bytes;
    off_t loading_loaded_bytes;
    time_t loading_start_time;
    /* Fast pointers to often looked up command */
    struct redisCommand *delCommand, *multiCommand;
    list *slaves, *monitors;
    redisClient *current_client; /* Current client, only used on crash report */
    char neterr[ANET_ERR_LEN];
    aeEventLoop *el; // redis的EventLoop.
    int cronloops;              /* number of times the cron function run */
    time_t lastsave;                /* Unix time of last save succeeede */
    /* Fields used only for stats */
    time_t stat_starttime;          /* server start time */
    long long stat_numcommands;     /* number of processed commands */
    long long stat_numconnections;  /* number of connections received */
    long long stat_expiredkeys;     /* number of expired keys */
    long long stat_evictedkeys;     /* number of evicted keys (maxmemory) */
    long long stat_keyspace_hits;   /* number of successful lookups of keys */
    long long stat_keyspace_misses; /* number of failed lookups of keys */
    size_t stat_peak_memory;        /* max used memory record */
    long long stat_fork_time;       /* time needed to perform latets fork() */
    list *slowlog;
    long long slowlog_entry_id;
    long long slowlog_log_slower_than;
    unsigned long slowlog_max_len;
    /* Configuration */
    int verbosity;
    int maxidletime;
    size_t client_max_querybuf_len;
    int dbnum;
    int daemonize;
    int appendonly; // 是否开启AOF功能.
    int appendfsync;
    int no_appendfsync_on_rewrite; // 如果在rewrite过程的话那么不要AOF fsync.
    int auto_aofrewrite_perc;       /* Rewrite AOF if % growth is > M and... */
    off_t auto_aofrewrite_min_size; /* the AOF file is at least N bytes. */
    off_t auto_aofrewrite_base_size;/* AOF size on latest startup or rewrite. */
    off_t appendonly_current_size;  /* AOF current size. */
    int aofrewrite_scheduled;       /* Rewrite once BGSAVE terminates. */
    int shutdown_asap;
    time_t lastfsync; // 上次调用fsync或者是background fsync的时间.
    int appendfd; // AOF fd.
    int appendseldb;
    time_t aof_flush_postponed_start; // 调用AOF flush但是结果postpone的话的时间.
    // 如果flush造成postpone时间过长的话，那么会有日志打印出来.
    char *pidfile;
    pid_t bgsavechildpid;
    pid_t bgrewritechildpid; // 后台rewrite子进程.
    sds bgrewritebuf; /* buffer taken by parent during oppend only rewrite */
    sds aofbuf;       /* AOF buffer, written before entering the event loop */
    struct saveparam *saveparams;
    int saveparamslen;
    char *logfile; // log文件
    int syslog_enabled; // 是否允许syslog
    char *syslog_ident;
    int syslog_facility;
    char *dbfilename;
    char *appendfilename; // AOF文件.
    char *requirepass;
    int rdbcompression;
    int activerehashing;
    /* Replication related */
    int isslave;
    /* Slave specific fields */
    char *masterauth;
    char *masterhost;
    int masterport;
    int repl_ping_slave_period;
    int repl_timeout;
    redisClient *master;    /* client that is master for this slave */
    int repl_syncio_timeout; /* timeout for synchronous I/O calls */
    int replstate;          /* replication status if the instance is a slave */
    off_t repl_transfer_left;  /* bytes left reading .rdb  */
    int repl_transfer_s;    /* slave -> master SYNC socket */
    int repl_transfer_fd;   /* slave -> master SYNC temp file descriptor */
    char *repl_transfer_tmpfile; /* slave-> master SYNC temp file name */
    time_t repl_transfer_lastio; /* unix time of the latest read, for timeout */
    int repl_serve_stale_data; /* Serve stale data when link is down? */
    time_t repl_down_since; /* unix time at which link with master went down */
    /* Limits */
    unsigned int maxclients;
    unsigned long long maxmemory;
    int maxmemory_policy;
    int maxmemory_samples;
    /* Blocked clients */
    unsigned int bpop_blocked_clients;
    unsigned int vm_blocked_clients;
    list *unblocked_clients;
    /* Sort parameters - qsort_r() is only available under BSD so we
     * have to take this state global, in order to pass it to sortCompare() */
    int sort_desc;
    int sort_alpha;
    int sort_bypattern;
    /* Virtual memory configuration */
    int vm_enabled;
    char *vm_swap_file; // vm swap file.
    off_t vm_page_size; // page size.
    off_t vm_pages; // page number.
    unsigned long long vm_max_memory;
    /* Zip structure config */
    size_t hash_max_zipmap_entries;
    size_t hash_max_zipmap_value;
    size_t list_max_ziplist_entries;
    size_t list_max_ziplist_value;
    size_t set_max_intset_entries;
    size_t zset_max_ziplist_entries;
    size_t zset_max_ziplist_value;
    /* Virtual memory state */
    FILE *vm_fp; // vm swap file handler.
    int vm_fd; // vm swap file fd.
    off_t vm_next_page; /* Next probably empty page */
    off_t vm_near_pages; /* Number of pages allocated sequentially */
    unsigned char *vm_bitmap; /* Bitmap of free/used pages */
    time_t unixtime;    /* Unix time sampled every second. */
    /* Virtual memory I/O threads stuff */
    /* An I/O thread process an element taken from the io_jobs queue and
     * put the result of the operation in the io_done list. While the
     * job is being processed, it's put on io_processing queue. */
    list *io_newjobs; /* List of VM I/O jobs yet to be processed */
    list *io_processing; /* List of VM I/O jobs being processed */
    list *io_processed; /* List of VM I/O jobs already processed */
    list *io_ready_clients; /* Clients ready to be unblocked. All keys loaded */
    pthread_mutex_t io_mutex; /* lock to access io_jobs/io_done/io_thread_job */
    pthread_mutex_t io_swapfile_mutex; /* So we can lseek + write */
    pthread_attr_t io_threads_attr; /* attributes for threads creation */
    int io_active_threads; /* Number of running I/O threads */
    int vm_max_threads; /* Max number of I/O threads running at the same time */
    /* Our main thread is blocked on the event loop, locking for sockets ready
     * to be read or written, so when a threaded I/O operation is ready to be
     * processed by the main thread, the I/O thread will use a unix pipe to
     * awake the main thread. The followings are the two pipe FDs. */
    int io_ready_pipe_read;
    int io_ready_pipe_write;
    /* Virtual memory stats */
    unsigned long long vm_stats_used_pages;
    unsigned long long vm_stats_swapped_objects;
    unsigned long long vm_stats_swapouts;
    unsigned long long vm_stats_swapins;
    /* Pubsub */
    dict *pubsub_channels; /* Map channels to list of subscribed clients */
    list *pubsub_patterns; /* A list of pubsub_patterns */
    /* Misc */
    unsigned lruclock:22;        /* clock incrementing every minute, for LRU */
    unsigned lruclock_padding:10;
    /* Assert & bug reportign */
    char *assert_failed; // 断言失败的表达式
    char *assert_file; // 断言失败的文件
    int assert_line; // 断言失败的行号
    int bug_report_start; /* True if bug report header already logged. */
    // 是否开始进行bug report打印.
};
#+END_SRC

***** redisClient
redisClient应该是针对每个client请求保存的状态。TODO(dirlt):解释关于各个字段的含义.
#+BEGIN_SRC C++
/* With multiplexing we need to take per-clinet state.
 * Clients are taken in a liked list. */
typedef struct redisClient {
    int fd; // tcp连接fd.
    redisDb *db;
    int dictid;
    sds querybuf; // 读取到的数据
    int argc; // 参数个数
    robj **argv; // 参数值
    struct redisCommand *cmd, *lastcmd; // 当前命令和上一条命令
    int reqtype; // 请求类型
    int multibulklen;       /* number of multi bulk arguments left to read */
    long bulklen;           /* length of bulk argument in multi bulk request */
    list *reply; // 回复应答，按照链表组织
    unsigned long reply_bytes; /* Tot bytes of objects in reply list */ // 回复应答总共占用多少字节.
    int sentlen;
    time_t lastinteraction; /* time of the last interaction, used for timeout */
    int flags;              /* REDIS_SLAVE | REDIS_MONITOR | REDIS_MULTI ... */
    int slaveseldb;         /* slave selected db, if this client is a slave */
    int authenticated;      /* when requirepass is non-NULL */
    int replstate;          /* replication state if this is a slave */
    int repldbfd;           /* replication DB file descriptor */
    long repldboff;         /* replication DB file offset */
    off_t repldbsize;       /* replication DB file size */
    multiState mstate;      /* MULTI/EXEC state */
    blockingState bpop;   /* blocking state */
    list *io_keys;          /* Keys this client is waiting to be loaded from the
                             * swap file in order to continue. */
    list *watched_keys;     /* Keys WATCHED for MULTI/EXEC CAS */
    dict *pubsub_channels;  /* channels a client is interested in (SUBSCRIBE) */
    list *pubsub_patterns;  /* patterns a client is interested in (SUBSCRIBE) */

    /* Response buffer */
    int bufpos;
    char buf[REDIS_REPLY_CHUNK_BYTES];
} redisClient;
#+END_SRC
***** redisObject
TODO(dirlt):
#+BEGIN_SRC C++
/* A redis object, that is a type able to hold a string / list / set */

/* The actual Redis Object */
#define REDIS_LRU_CLOCK_MAX ((1<<21)-1) /* Max value of obj->lru */
#define REDIS_LRU_CLOCK_RESOLUTION 10 /* LRU clock resolution in seconds */
typedef struct redisObject {
    unsigned type:4;
    unsigned storage:2;     /* REDIS_VM_MEMORY or REDIS_VM_SWAPPING */
    unsigned encoding:4;
    unsigned lru:22;        /* lru time (relative to server.lruclock) */
    int refcount;
    void *ptr;
    /* VM fields are only allocated if VM is active, otherwise the
     * object allocation function will just allocate
     * sizeof(redisObjct) minus sizeof(redisObjectVM), so using
     * Redis without VM active will not have any overhead. */
} robj;
#+END_SRC

**** Interface
TODO(dirlt):

**** redisLog
注意这里打本地日志的话都每次都会用fopen打开并且fclose关闭。然后可以可选地通过syslog进行打印。
#+BEGIN_SRC C++
// redis.h
/* Log levels */
#define REDIS_DEBUG 0
#define REDIS_VERBOSE 1
#define REDIS_NOTICE 2
#define REDIS_WARNING 3

void redisLog(int level, const char *fmt, ...) {
    const int syslogLevelMap[] = { LOG_DEBUG, LOG_INFO, LOG_NOTICE, LOG_WARNING }; // syslog日志等级
    const char *c = ".-*#"; // 日志等级前缀.
    time_t now = time(NULL);
    va_list ap;
    FILE *fp;
    char buf[64];
    char msg[REDIS_MAX_LOGMSG_LEN];

    if (level < server.verbosity) return;

    fp = (server.logfile == NULL) ? stdout : fopen(server.logfile,"a");
    if (!fp) return;

    va_start(ap, fmt);
    vsnprintf(msg, sizeof(msg), fmt, ap);
    va_end(ap);

    strftime(buf,sizeof(buf),"%d %b %H:%M:%S",localtime(&now));
    fprintf(fp,"[%d] %s %c %s\n",(int)getpid(),buf,c[level],msg);
    fflush(fp);

    if (server.logfile) fclose(fp);

    if (server.syslog_enabled) syslog(syslogLevelMap[level], "%s", msg);
}
#+END_SRC

*** Assertion
在redis.h里面提供了自己内部的异常断言机制。在debug.c里面有具体实现.
#+BEGIN_SRC C++
/* We can print the stacktrace, so our assert is defined this way: */
#define redisAssert(_e) ((_e)?(void)0 : (_redisAssert(#_e,__FILE__,__LINE__),_exit(1)))
#define redisPanic(_e) _redisPanic(#_e,__FILE__,__LINE__),_exit(1)
void _redisAssert(char *estr, char *file, int line);
void _redisPanic(char *msg, char *file, int line);
void bugReportStart(void);
#+END_SRC

**** bugReportStart
开启bug report打印.实现在redis.c里面.
#+BEGIN_SRC C++
void bugReportStart(void) {
    if (server.bug_report_start == 0) {
        redisLog(REDIS_WARNING,
            "=== REDIS BUG REPORT START: Cut & paste starting from here ===");
        server.bug_report_start = 1;
    }
}
#+END_SRC

****  _redisAssert
打印assert失败的结果.非常精彩的一点就是可以制造SIGSEGV信号来简介地触发backtrace.
redis应该是截获了SIGSEGV信号，如果触发了这个信号的话会调用backtrace.
#+BEGIN_SRC C++
void _redisAssert(char *estr, char *file, int line) {
#ifdef HAVE_BACKTRACE
    bugReportStart(); // 开启bug report.
#endif
    redisLog(REDIS_WARNING,"=== ASSERTION FAILED ===");
    redisLog(REDIS_WARNING,"==> %s:%d '%s' is not true",file,line,estr);
#ifdef HAVE_BACKTRACE
    server.assert_failed = estr;
    server.assert_file = file;
    server.assert_line = line;
    redisLog(REDIS_WARNING,"(forcing SIGSEGV to print the bug report.)");
#endif
    *((char*)-1) = 'x';
}
#+END_SRC

**** _redisPanic
panic应该是出现一些不可恢复情况时候的情况.实现上和assert是非常类似的.
#+BEGIN_SRC C++
void _redisPanic(char *msg, char *file, int line) {
#ifdef HAVE_BACKTRACE
    bugReportStart();
#endif
    redisLog(REDIS_WARNING,"!!! Software Failure. Press left mouse button to continue");
    redisLog(REDIS_WARNING,"Guru Meditation: %s #%s:%d",msg,file,line);
#ifdef HAVE_BACKTRACE
    redisLog(REDIS_WARNING,"(forcing SIGSEGV in order to print the stack trace)");
#endif
    *((char*)-1) = 'x';
}
#+END_SRC

*** Networking
在redis.h内部定义了networking部分的接口，然后在networking.c内部定义了实现。TODO(dirlt):what for use?.

**** Interface
#+BEGIN_SRC C++
/* networking.c -- Networking and Client related operations */
redisClient *createClient(int fd);
void closeTimedoutClients(void);
void freeClient(redisClient *c);
void resetClient(redisClient *c);
void sendReplyToClient(aeEventLoop *el, int fd, void *privdata, int mask);
void addReply(redisClient *c, robj *obj);
void *addDeferredMultiBulkLength(redisClient *c);
void setDeferredMultiBulkLength(redisClient *c, void *node, long length);
void addReplySds(redisClient *c, sds s);
void processInputBuffer(redisClient *c);
void acceptTcpHandler(aeEventLoop *el, int fd, void *privdata, int mask);
void acceptUnixHandler(aeEventLoop *el, int fd, void *privdata, int mask);
void readQueryFromClient(aeEventLoop *el, int fd, void *privdata, int mask);
void addReplyBulk(redisClient *c, robj *obj);
void addReplyBulkCString(redisClient *c, char *s);
void addReplyBulkCBuffer(redisClient *c, void *p, size_t len);
void addReplyBulkLongLong(redisClient *c, long long ll);
void acceptHandler(aeEventLoop *el, int fd, void *privdata, int mask);
void addReply(redisClient *c, robj *obj);
void addReplySds(redisClient *c, sds s);
void addReplyError(redisClient *c, char *err);
void addReplyStatus(redisClient *c, char *status);
void addReplyDouble(redisClient *c, double d);
void addReplyLongLong(redisClient *c, long long ll);
void addReplyMultiBulkLen(redisClient *c, long length);
void copyClientOutputBuffer(redisClient *dst, redisClient *src);
void *dupClientReplyValue(void *o);
void getClientsMaxBuffers(unsigned long *longest_output_list,
                          unsigned long *biggest_input_buffer);
sds getClientInfoString(redisClient *client);
sds getAllClientsInfoString(void);
void rewriteClientCommandVector(redisClient *c, int argc, ...);
unsigned long getClientOutputBufferMemoryUsage(redisClient *c);
void flushSlavesOutputBuffers(void);
void disconnectSlaves(void);

#ifdef __GNUC__
void addReplyErrorFormat(redisClient *c, const char *fmt, ...)
    __attribute__((format(printf, 2, 3)));
void addReplyStatusFormat(redisClient *c, const char *fmt, ...)
    __attribute__((format(printf, 2, 3)));
#else
void addReplyErrorFormat(redisClient *c, const char *fmt, ...);
void addReplyStatusFormat(redisClient *c, const char *fmt, ...);
#endif
#+END_SRC

*** AsyncEvent
redis的ae(异步事件,AsyncEvent)是异步管理的基础，在ae.h里面实现。下面的注释是关于ae的描述.
#+BEGIN_SRC C++
/* A simple event-driven programming library. Originally I wrote this code
 * for the Jim's event-loop (Jim is a Tcl interpreter) but later translated
 * it in form of a library for easy reuse.
*/
#+END_SRC

**** defines
#+BEGIN_SRC C++
#define AE_SETSIZE (1024*10)    /* Max number of fd supported */

#define AE_OK 0
#define AE_ERR -1

// 对于fd的触发mask.
#define AE_NONE 0
#define AE_READABLE 1
#define AE_WRITABLE 2

// 调用事件循环处理的flag.
#define AE_FILE_EVENTS 1 // 只是处理file
#define AE_TIME_EVENTS 2 // 只是处理time
#define AE_ALL_EVENTS (AE_FILE_EVENTS|AE_TIME_EVENTS) // 都处理
#define AE_DONT_WAIT 4 // 是否等待事件到来

#define AE_NOMORE -1 // 事件处理完成之后是否还需要触发.

/* Macros */
#define AE_NOTUSED(V) ((void) V)
#+END_SRC

**** Interface
***** typedef
#+BEGIN_SRC C++
/* Types and data structures */
typedef void aeFileProc(struct aeEventLoop *eventLoop, int fd, void *clientData, int mask); // fd事件回调.
typedef int aeTimeProc(struct aeEventLoop *eventLoop, long long id, void *clientData); // 超时事件回调.
typedef void aeEventFinalizerProc(struct aeEventLoop *eventLoop, void *clientData); // 事件完成回调.
typedef void aeBeforeSleepProc(struct aeEventLoop *eventLoop); // 休眠之前回调.

/* File event structure */
typedef struct aeFileEvent {
    int mask; /* one of AE_(READABLE|WRITABLE) */
    aeFileProc *rfileProc; // 如果可读触发的回调
    aeFileProc *wfileProc; // 如果可写触发的回调
    void *clientData; // client data.
} aeFileEvent;

/* Time event structure */
typedef struct aeTimeEvent {
    long long id; /* time event identifier. */
    long when_sec; /* seconds */
    long when_ms; /* milliseconds */
    aeTimeProc *timeProc; // 超时触发的回调
    aeEventFinalizerProc *finalizerProc; // 时间完成回调
    void *clientData; // client data
    struct aeTimeEvent *next; // 后一个超时事件.
} aeTimeEvent;

/* A fired event */
typedef struct aeFiredEvent { // 被删除的event.这个是否是异步取消?.
    int fd;
    int mask;
} aeFiredEvent;

/* State of an event based program */
typedef struct aeEventLoop { // 这个是异步事件的核心接口.
    int maxfd; // 最大的fd.
    long long timeEventNextId; // 超时事件id.
    aeFileEvent events[AE_SETSIZE]; /* Registered events */
    aeFiredEvent fired[AE_SETSIZE]; /* Fired events */
    aeTimeEvent *timeEventHead; // 对于超时事件被组织称为链表.
    int stop; // 是否停止.
    void *apidata; /* This is used for polling API specific data */ // 异步事件底层的多路复用对象.
    aeBeforeSleepProc *beforesleep; // 在sleep之前的回调
} aeEventLoop;
#+END_SRC

***** api
#+BEGIN_SRC C++
// --------------------
/* Prototypes */
aeEventLoop *aeCreateEventLoop(void); // 创建异步循环对象.
void aeDeleteEventLoop(aeEventLoop *eventLoop); // 销毁
void aeStop(aeEventLoop *eventLoop); // 停止

// --------------------
int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask,
        aeFileProc *proc, void *clientData); // 创建fd异步事件
void aeDeleteFileEvent(aeEventLoop *eventLoop, int fd, int mask);
int aeGetFileEvents(aeEventLoop *eventLoop, int fd); // 得到这个fd的异步条件

// --------------------
long long aeCreateTimeEvent(aeEventLoop *eventLoop, long long milliseconds,
        aeTimeProc *proc, void *clientData,
        aeEventFinalizerProc *finalizerProc); // 创建超时事件.应该返回超时事件id.
int aeDeleteTimeEvent(aeEventLoop *eventLoop, long long id);

// --------------------
int aeProcessEvents(aeEventLoop *eventLoop, int flags); // 启动事件循环处理.应该只是处理一次.
int aeWait(int fd, int mask, long long milliseconds); // 阻塞式地等待在超时时间内fd的读写时间到来.
void aeMain(aeEventLoop *eventLoop); // 不断地调用aeProcessEvents.
char *aeGetApiName(void); // 多路复用模型API.
void aeSetBeforeSleepProc(aeEventLoop *eventLoop, aeBeforeSleepProc *beforesleep); // 每次调用事件处理循环之前的会回调.
#+END_SRC

**** Loop
对于Loop来说redis提供了select(ae_select.c),kqueue(ae_kqueue.c)以及epoll(ae_epoll.c).我们这里仅仅关注ae_epoll.c提供的功能.
***** defines
#+BEGIN_SRC C++
typedef struct aeApiState {
    int epfd; // epoll fd.
    struct epoll_event events[AE_SETSIZE]; // 一次只是处理这些AE_SETSIZE事件.
} aeApiState;
#+END_SRC

***** aeApiCreate
创建Loop对象放在apidata这个字段.
#+BEGIN_SRC C++
static int aeApiCreate(aeEventLoop *eventLoop) {
    aeApiState *state = zmalloc(sizeof(aeApiState));

    if (!state) return -1;
    state->epfd = epoll_create(1024); /* 1024 is just an hint for the kernel */
    if (state->epfd == -1) return -1;
    eventLoop->apidata = state;
    return 0;
}
#+END_SRC

***** aeApiFree
#+BEGIN_SRC C++
static void aeApiFree(aeEventLoop *eventLoop) {
    aeApiState *state = eventLoop->apidata;

    close(state->epfd);
    zfree(state);
}
#+END_SRC

***** aeApiAddEvent
#+BEGIN_SRC C++
static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) {
    aeApiState *state = eventLoop->apidata;
    struct epoll_event ee;
    /* If the fd was already monitored for some event, we need a MOD
     * operation. Otherwise we need an ADD operation. */
    int op = eventLoop->events[fd].mask == AE_NONE ? // 如果没有设置任何内容那么就ADD否则就MOD.
            EPOLL_CTL_ADD : EPOLL_CTL_MOD;

    ee.events = 0;
    mask |= eventLoop->events[fd].mask; /* Merge old events */
    if (mask & AE_READABLE) ee.events |= EPOLLIN;
    if (mask & AE_WRITABLE) ee.events |= EPOLLOUT;
    ee.data.u64 = 0; /* avoid valgrind warning */
    ee.data.fd = fd;
    if (epoll_ctl(state->epfd,op,fd,&ee) == -1) return -1;
    return 0;
}
#+END_SRC

***** aeApiDelEvent
#+BEGIN_SRC C++
static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int delmask) {
    aeApiState *state = eventLoop->apidata;
    struct epoll_event ee;
    int mask = eventLoop->events[fd].mask & (~delmask); // 得到处理之后的mask.

    ee.events = 0;
    if (mask & AE_READABLE) ee.events |= EPOLLIN;
    if (mask & AE_WRITABLE) ee.events |= EPOLLOUT;
    ee.data.u64 = 0; /* avoid valgrind warning */
    ee.data.fd = fd;
    if (mask != AE_NONE) { // 如果这个mask!=AE_NONE那么仅仅是修改
        epoll_ctl(state->epfd,EPOLL_CTL_MOD,fd,&ee);
    } else {
        /* Note, Kernel < 2.6.9 requires a non null event pointer even for
         * EPOLL_CTL_DEL. */
        epoll_ctl(state->epfd,EPOLL_CTL_DEL,fd,&ee); // 否则就完全删除.
    }
}
#+END_SRC

***** aeApiPoll
#+BEGIN_SRC C++
static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) {
    aeApiState *state = eventLoop->apidata;
    int retval, numevents = 0;

    retval = epoll_wait(state->epfd,state->events,AE_SETSIZE, // 最多得到AE_SETSIZE这些触发事件
            tvp ? (tvp->tv_sec*1000 + tvp->tv_usec/1000) : -1);
    if (retval > 0) {
        int j;

        numevents = retval;
        for (j = 0; j < numevents; j++) {
            int mask = 0;
            struct epoll_event *e = state->events+j;

            if (e->events & EPOLLIN) mask |= AE_READABLE;
            if (e->events & EPOLLOUT) mask |= AE_WRITABLE;
            eventLoop->fired[j].fd = e->data.fd; // 将触发的事件全部放置到fired这个数组内部.
            eventLoop->fired[j].mask = mask;
        }
    }
    return numevents;
}
#+END_SRC

**** aeCreateEventLoop
初始化非常trivial.对于销毁的话也只是销毁apistate这个字段然后销毁整个结构体即可.
#+BEGIN_SRC C++
aeEventLoop *aeCreateEventLoop(void) {
    aeEventLoop *eventLoop;
    int i;

    eventLoop = zmalloc(sizeof(*eventLoop));
    if (!eventLoop) return NULL;
    eventLoop->timeEventHead = NULL;
    eventLoop->timeEventNextId = 0;
    eventLoop->stop = 0; // 启动不停止.
    eventLoop->maxfd = -1;
    eventLoop->beforesleep = NULL;
    if (aeApiCreate(eventLoop) == -1) {
        zfree(eventLoop);
        return NULL;
    }
    /* Events with mask == AE_NONE are not set. So let's initialize the
     * vector with it. */
    for (i = 0; i < AE_SETSIZE; i++)
        eventLoop->events[i].mask = AE_NONE;
    return eventLoop;
}
#+END_SRC

**** aeCreateFileEvent
#+BEGIN_SRC C++
int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask,
        aeFileProc *proc, void *clientData)
{
    if (fd >= AE_SETSIZE) return AE_ERR; // 不支持过大的fd.
    // 在linux下面fd是按照顺序分配的所以没有问题
    // 如果是跳跃分配fd的话那么会有功能限制.
    aeFileEvent *fe = &eventLoop->events[fd];

    if (aeApiAddEvent(eventLoop, fd, mask) == -1) // 添加fd到loop内部.
        return AE_ERR;
    // 然后这是mask以及回调还有client data.
    // 修改maxfd.
    fe->mask |= mask;
    if (mask & AE_READABLE) fe->rfileProc = proc;
    if (mask & AE_WRITABLE) fe->wfileProc = proc;
    fe->clientData = clientData;
    if (fd > eventLoop->maxfd)
        eventLoop->maxfd = fd;
    return AE_OK;
}
#+END_SRC

**** aeDeleteFileEvent
#+BEGIN_SRC C++
void aeDeleteFileEvent(aeEventLoop *eventLoop, int fd, int mask)
{
    if (fd >= AE_SETSIZE) return;
    aeFileEvent *fe = &eventLoop->events[fd];

    if (fe->mask == AE_NONE) return;
    fe->mask = fe->mask & (~mask);
    // 更新maxfd.
    if (fd == eventLoop->maxfd && fe->mask == AE_NONE) {
        /* Update the max fd */
        int j;

        for (j = eventLoop->maxfd-1; j >= 0; j--)
            if (eventLoop->events[j].mask != AE_NONE) break;
        eventLoop->maxfd = j;
    }
    // 从loop中删除.
    aeApiDelEvent(eventLoop, fd, mask);
}
#+END_SRC

**** aeCreateTimeEvent
#+BEGIN_SRC C++
static void aeGetTime(long *seconds, long *milliseconds)
{
    struct timeval tv;

    gettimeofday(&tv, NULL);
    *seconds = tv.tv_sec;
    *milliseconds = tv.tv_usec/1000;
}

static void aeAddMillisecondsToNow(long long milliseconds, long *sec, long *ms) {
    long cur_sec, cur_ms, when_sec, when_ms;

    aeGetTime(&cur_sec, &cur_ms);
    when_sec = cur_sec + milliseconds/1000;
    when_ms = cur_ms + milliseconds%1000;
    if (when_ms >= 1000) {
        when_sec ++;
        when_ms -= 1000;
    }
    *sec = when_sec;
    *ms = when_ms;
}

long long aeCreateTimeEvent(aeEventLoop *eventLoop, long long milliseconds,
        aeTimeProc *proc, void *clientData,
        aeEventFinalizerProc *finalizerProc)
{
    long long id = eventLoop->timeEventNextId++; // 分配id并且返回这个id.
    aeTimeEvent *te;

    te = zmalloc(sizeof(*te));
    if (te == NULL) return AE_ERR;
    te->id = id;
    // 计算出超时的时间.what seconds and mill seconds.
    aeAddMillisecondsToNow(milliseconds,&te->when_sec,&te->when_ms);
    te->timeProc = proc; // 设置回调函数.
    te->finalizerProc = finalizerProc;
    te->clientData = clientData;
    te->next = eventLoop->timeEventHead; // 把这个Event放在TimeEvent的头部.
    eventLoop->timeEventHead = te;
    return id;
}
#+END_SRC

**** aeDeleteTimeEvent
删除超时事件是拿id去匹配的.效率上来说的话如果超时事件如果不多的话，效率还可以接受.
#+BEGIN_SRC C++
int aeDeleteTimeEvent(aeEventLoop *eventLoop, long long id)
{
    aeTimeEvent *te, *prev = NULL;

    te = eventLoop->timeEventHead;
    while(te) {
        if (te->id == id) {
            if (prev == NULL)
                eventLoop->timeEventHead = te->next;
            else
                prev->next = te->next;
            if (te->finalizerProc) // 这个时间被delete掉的话那么回触发finalizer这个回调.
                te->finalizerProc(eventLoop, te->clientData);
            zfree(te);
            return AE_OK;
        }
        prev = te;
        te = te->next;
    }
    return AE_ERR; /* NO event with the specified ID found */
}
#+END_SRC

**** aeProcessEvents
首先调用pending time event然后处理file event.对于flags而言的话，在注释里面也解释了含义.
DONT_WAIT应该是如果当时没有任何事件需要处理的话那么就直接返回。返回处理了多少个事件。
从处理逻辑里面可以看到，相对于libev这种库首先处理timer事件然后处理file event，而redis
定义的事件模型是首先处理fd然后再来处理timer事件.

#+BEGIN_SRC C++
/* Process every pending time event, then every pending file event
 * (that may be registered by time event callbacks just processed).
 * Without special flags the function sleeps until some file event
 * fires, or when the next time event occurrs (if any).
 *
 * If flags is 0, the function does nothing and returns.
 * if flags has AE_ALL_EVENTS set, all the kind of events are processed.
 * if flags has AE_FILE_EVENTS set, file events are processed.
 * if flags has AE_TIME_EVENTS set, time events are processed.
 * if flags has AE_DONT_WAIT set the function returns ASAP until all
 * the events that's possible to process without to wait are processed.
 *
 * The function returns the number of events processed. */
int aeProcessEvents(aeEventLoop *eventLoop, int flags)
{
    int processed = 0, numevents;

    /* Nothing to do? return ASAP */
    if (!(flags & AE_TIME_EVENTS) && !(flags & AE_FILE_EVENTS)) return 0;

    /* Note that we want call select() even if there are no
     * file events to process as long as we want to process time
     * events, in order to sleep until the next time event is ready
     * to fire. */
    // 如果需要处理file event的话,或者是允许wait等待time event的话.
    if (eventLoop->maxfd != -1 ||
        ((flags & AE_TIME_EVENTS) && !(flags & AE_DONT_WAIT))) {
        int j;
        aeTimeEvent *shortest = NULL;
        struct timeval tv, *tvp;

        if (flags & AE_TIME_EVENTS && !(flags & AE_DONT_WAIT))
            shortest = aeSearchNearestTimer(eventLoop); // 查找到最小的超时事件.
        // 计算需要等待多少时间.
        if (shortest) {
            long now_sec, now_ms;

            /* Calculate the time missing for the nearest
             * timer to fire. */
            aeGetTime(&now_sec, &now_ms);
            tvp = &tv;
            tvp->tv_sec = shortest->when_sec - now_sec;
            if (shortest->when_ms < now_ms) {
                tvp->tv_usec = ((shortest->when_ms+1000) - now_ms)*1000;
                tvp->tv_sec --;
            } else {
                tvp->tv_usec = (shortest->when_ms - now_ms)*1000;
            }
            if (tvp->tv_sec < 0) tvp->tv_sec = 0;
            if (tvp->tv_usec < 0) tvp->tv_usec = 0;
        } else {
            /* If we have to check for events but need to return
             * ASAP because of AE_DONT_WAIT we need to se the timeout
             * to zero */
            if (flags & AE_DONT_WAIT) {
                tv.tv_sec = tv.tv_usec = 0;
                tvp = &tv;
            } else {
                /* Otherwise we can block */
                tvp = NULL; /* wait forever */
            }
        }

        numevents = aeApiPoll(eventLoop, tvp);
        for (j = 0; j < numevents; j++) {
            aeFileEvent *fe = &eventLoop->events[eventLoop->fired[j].fd];
            int mask = eventLoop->fired[j].mask;
            int fd = eventLoop->fired[j].fd;
            int rfired = 0;

	    /* note the fe->mask & mask & ... code: maybe an already processed
             * event removed an element that fired and we still didn't
             * processed, so we check if the event is still valid. */
            if (fe->mask & mask & AE_READABLE) {
                rfired = 1;
                fe->rfileProc(eventLoop,fd,fe->clientData,mask);
            }
            if (fe->mask & mask & AE_WRITABLE) {
                if (!rfired || fe->wfileProc != fe->rfileProc)
                    fe->wfileProc(eventLoop,fd,fe->clientData,mask);
            }
            processed++;
        }
    }
    /* Check time events */
    if (flags & AE_TIME_EVENTS)
        processed += processTimeEvents(eventLoop);

    return processed; /* return the number of processed file/time events */
}
#+END_SRC

--------------------
我们看看里面怎么找到最小触发的timer.效率不是很高.作者也在注释里面提到了优化算法.
#+BEGIN_SRC C++
/* Search the first timer to fire.
 * This operation is useful to know how many time the select can be
 * put in sleep without to delay any event.
 * If there are no timers NULL is returned.
 *
 * Note that's O(N) since time events are unsorted.
 * Possible optimizations (not needed by Redis so far, but...):
 * 1) Insert the event in order, so that the nearest is just the head.
 *    Much better but still insertion or deletion of timers is O(N).
 * 2) Use a skiplist to have this operation as O(1) and insertion as O(log(N)).
 */
static aeTimeEvent *aeSearchNearestTimer(aeEventLoop *eventLoop)
{
    aeTimeEvent *te = eventLoop->timeEventHead;
    aeTimeEvent *nearest = NULL;

    while(te) {
        if (!nearest || te->when_sec < nearest->when_sec ||
                (te->when_sec == nearest->when_sec &&
                 te->when_ms < nearest->when_ms))
            nearest = te;
        te = te->next;
    }
    return nearest;
}
#+END_SRC

--------------------
最后看看怎么处理超时事件的.遍历整个超时事件链表即可,但是需要考虑超时事件需要重复触发.
#+BEGIN_SRC C++
/* Process time events */
static int processTimeEvents(aeEventLoop *eventLoop) {
    int processed = 0;
    aeTimeEvent *te;
    long long maxId;

    te = eventLoop->timeEventHead;
    maxId = eventLoop->timeEventNextId-1;
    while(te) {
        long now_sec, now_ms;
        long long id;

        if (te->id > maxId) { // TODO(dirlt):不合法timer event?.
            te = te->next;
            continue;
        }
        aeGetTime(&now_sec, &now_ms);
        if (now_sec > te->when_sec ||
            (now_sec == te->when_sec && now_ms >= te->when_ms)) // 如果到达触发条件.
        {
            int retval;

            id = te->id;
            retval = te->timeProc(eventLoop, id, te->clientData);
            processed++;
            /* After an event is processed our time event list may
             * no longer be the same, so we restart from head.
             * Still we make sure to don't process events registered
             * by event handlers itself in order to don't loop forever.
             * To do so we saved the max ID we want to handle.
             *
             * FUTURE OPTIMIZATIONS:
             * Note that this is NOT great algorithmically. Redis uses
             * a single time event so it's not a problem but the right
             * way to do this is to add the new elements on head, and
             * to flag deleted elements in a special way for later
             * deletion (putting references to the nodes to delete into
             * another linked list). */
            if (retval != AE_NOMORE) { // 是否需要继续触发.
                aeAddMillisecondsToNow(retval,&te->when_sec,&te->when_ms);
            } else {
                aeDeleteTimeEvent(eventLoop, id);
            }
            te = eventLoop->timeEventHead;
        } else {
            te = te->next;
        }
    }
    return processed;
}
#+END_SRC

**** aeWait
同步等待fd条件满足.
#+BEGIN_SRC C++
/* Wait for millseconds until the given file descriptor becomes
 * writable/readable/exception */
int aeWait(int fd, int mask, long long milliseconds) {
    struct timeval tv;
    fd_set rfds, wfds, efds;
    int retmask = 0, retval;

    tv.tv_sec = milliseconds/1000;
    tv.tv_usec = (milliseconds%1000)*1000;
    FD_ZERO(&rfds);
    FD_ZERO(&wfds);
    FD_ZERO(&efds);

    if (mask & AE_READABLE) FD_SET(fd,&rfds);
    if (mask & AE_WRITABLE) FD_SET(fd,&wfds);
    if ((retval = select(fd+1, &rfds, &wfds, &efds, &tv)) > 0) {
        if (FD_ISSET(fd,&rfds)) retmask |= AE_READABLE;
        if (FD_ISSET(fd,&wfds)) retmask |= AE_WRITABLE;
        return retmask;
    } else {
        return retval;
    }
}
#+END_SRC

**** aeMain
不断地调用事件循环处理.注意在之前会调用beforeSleep.这个名字比较怪，或许叫做beforeProcess会更好:).
#+BEGIN_SRC C++
void aeMain(aeEventLoop *eventLoop) {
    eventLoop->stop = 0;
    while (!eventLoop->stop) {
        if (eventLoop->beforesleep != NULL)
            eventLoop->beforesleep(eventLoop);
        aeProcessEvents(eventLoop, AE_ALL_EVENTS);
    }
}
#+END_SRC

*** Socket IO
redis在anet.h里面对于tcp socket进行了一些简单的封装.
#+BEGIN_SRC C++
/* anet.c -- Basic TCP socket stuff made a bit less boring */
#+END_SRC
但是阅读代码实际上对于unix domain socket也进行了简单的封装.

**** Interface
#+BEGIN_SRC C++
#define ANET_OK 0
#define ANET_ERR -1
#define ANET_ERR_LEN 256

#if defined(__sun)
#define AF_LOCAL AF_UNIX
#endif

// 如果出现错误的话，那么将日志写入err这个字符串buffer内部.
int anetTcpConnect(char *err, char *addr, int port); // 发起tcp connect
int anetTcpNonBlockConnect(char *err, char *addr, int port); // 发起nonblock的tcp connect
int anetUnixConnect(char *err, char *path); // 发起unix domain connect
int anetUnixNonBlockConnect(char *err, char *path); // 发起unix domain connect
int anetRead(int fd, char *buf, int count); // 阻塞读取count字节.
int anetResolve(char *err, char *host, char *ipbuf); // 阻塞进行dns解析.
int anetTcpServer(char *err, int port, char *bindaddr); // tcp create/bind/listen.
int anetUnixServer(char *err, char *path, mode_t perm); // unix domain create/listen
int anetTcpAccept(char *err, int serversock, char *ip, int *port); // accept
int anetUnixAccept(char *err, int serversock);
int anetWrite(int fd, char *buf, int count);
int anetNonBlock(char *err, int fd);
int anetTcpNoDelay(char *err, int fd); // 设置TCP_NODELAY.
int anetTcpKeepAlive(char *err, int fd); // 设置SO_KEEPALIVE.
int anetPeerToString(int fd, char *ip, int *port); // fd的peed转换称为ip和port.
#+END_SRC

*** Sync IO
Sync IO包括socket以及文件的同步io功能.在redis.h里面有SyncIO部分的原型.
对于socket的sync io是存在超时的，对于本地文件读写不存在超时.对于redis来说的话
大部分的socket io都是non blocking方式操作的，但是在某些情况下面需要考虑同步io方式，
关于这点在syncio.c的注释里面给出了解释.
#+BEGIN_SRC C++
/* Redis performs most of the I/O in a nonblocking way, with the exception
 * of the SYNC command where the slave does it in a blocking way, and
 * the MIGRATE command that must be blocking in order to be atomic from the
 * point of view of the two instances (one migrating the key and one receiving
 * the key). This is why need the following blocking I/O functions. */
#+END_SRC

**** Interface
在redis.h内部给出了函数原型.
#+BEGIN_SRC C++
/* Synchronous I/O with timeout */
int syncWrite(int fd, char *ptr, ssize_t size, int timeout);
int syncRead(int fd, char *ptr, ssize_t size, int timeout);
int syncReadLine(int fd, char *ptr, ssize_t size, int timeout);
int fwriteBulkString(FILE *fp, char *s, unsigned long len);
int fwriteBulkDouble(FILE *fp, double d);
int fwriteBulkLongLong(FILE *fp, long long l);
int fwriteBulkObject(FILE *fp, robj *obj);
#+END_SRC

**** syncWrite
TODO(dirlt):

**** syncRead
TODO(dirlt):

**** syncReadLine
似乎这个sync read line实现太费了，每次只是读取一个字节(如果应用可能会发送多个连续行的话，
那么实现上只能够每次读取一个字节吧).
#+BEGIN_SRC C++
int syncReadLine(int fd, char *ptr, ssize_t size, int timeout) {
    ssize_t nread = 0;

    size--;
    while(size) {
        char c;

        if (syncRead(fd,&c,1,timeout) == -1) return -1;
        if (c == '\n') {
            *ptr = '\0';
            if (nread && *(ptr-1) == '\r') *(ptr-1) = '\0';
            return nread;
        } else {
            *ptr++ = c;
            *ptr = '\0';
            nread++;
        }
    }
    return nread;
}
#+END_SRC

**** fwriteBulkString
TODO(dirlt):

**** fwriteBulkDouble
TODO(dirlt):

**** fwriteBulkLongLong
TODO(dirlt):

**** fwriteBulkObject
向fp写入一个redis object对象.感觉文件io部分的话更多像是redis debug部分。将redis object
按照human readable的方式打印出来。
#+BEGIN_SRC C++
/* Delegate writing an object to writing a bulk string or bulk long long. */
int fwriteBulkObject(FILE *fp, robj *obj) {
    /* Avoid using getDecodedObject to help copy-on-write (we are often
     * in a child process when this function is called). */
    if (obj->encoding == REDIS_ENCODING_INT) {
        return fwriteBulkLongLong(fp,(long)obj->ptr);
    } else if (obj->encoding == REDIS_ENCODING_RAW) {
        return fwriteBulkString(fp,obj->ptr,sdslen(obj->ptr));
    } else {
        redisPanic("Unknown string encoding");
    }
}
#+END_SRC

*** Background IOo
后台io操作。从注释上来看的话现在只有close文件/删除文件以及fsync的后台操作。
对于删除文件可能会block住server所以需要放在后台操作.使用典型的生产消费模型，
有点类似于异步事件但是事件完成之后没有通知机制。不同类型放在不同的线程内部完成.

**** defines
#+BEGIN_SRC C++
/* Background job opcodes */
#define REDIS_BIO_CLOSE_FILE    0 /* Deferred close(2) syscall. */
#define REDIS_BIO_AOF_FSYNC     1 /* Deferred AOF fsync. */
#define REDIS_BIO_NUM_OPS       2 // 后台线程数量

// 异步队列的通知机制.
static pthread_mutex_t bio_mutex[REDIS_BIO_NUM_OPS];
static pthread_cond_t bio_condvar[REDIS_BIO_NUM_OPS];
// 每个队列上面挂载了多少个jobs.
static list *bio_jobs[REDIS_BIO_NUM_OPS];
/* The following array is used to hold the number of pending jobs for every
 * OP type. This allows us to export the bioPendingJobsOfType() API that is
 * useful when the main thread wants to perform some operation that may involve
 * objects shared with the background thread. The main thread will just wait
 * that there are no longer jobs of this type to be executed before performing
 * the sensible operation. This data is also useful for reporting. */
// 记录还有多少个pending.当时可以从bio_jobs里面计算出来.
static unsigned long long bio_pending[REDIS_BIO_NUM_OPS];

/* This structure represents a background Job. It is only used locally to this
 * file as the API deos not expose the internals at all. */
struct bio_job {
    // 这个job创建的时间.
    time_t time; /* Time at which the job was created. */
    /* Job specific arguments pointers. If we need to pass more than three
     * arguments we can just pass a pointer to a structure or alike. */
    void *arg1, *arg2, *arg3;
};

void *bioProcessBackgroundJobs(void *arg); // 线程回调.

/* Make sure we have enough stack to perform all the things we do in the
 * main thread. */
#define REDIS_THREAD_STACK_SIZE (1024*1024*4) // 4MB的线程空间大小.
#+END_SRC

**** Interface
#+BEGIN_SRC C++
/* Exported API */
void bioInit(void);
void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3);
unsigned long long bioPendingJobsOfType(int type);
void bioWaitPendingJobsLE(int type, unsigned long long num);
time_t bioOlderJobOfType(int type);
#+END_SRC

**** bioInit
启动多个线程并且创建job list.其中设置stacksize部分的话非常tricky考虑到了solaris的bug.
#+BEGIN_SRC C++
    /* Set the stack size as by default it may be small in some system */
    pthread_attr_init(&attr);
    pthread_attr_getstacksize(&attr,&stacksize);
    if (!stacksize) stacksize = 1; /* The world is full of Solaris Fixes */
    while (stacksize < REDIS_THREAD_STACK_SIZE) stacksize *= 2;
    pthread_attr_setstacksize(&attr, stacksize);
#+END_SRC

**** bioCreateBackgroundJob
创建一个bio_job并且丢到等待执行队列中.

**** bioPendingJobsOfType
某个type的pending jobs个数.

**** bioWaitPendingJobsLE
废弃不使用。

**** bioOlderJobOfType
废弃不使用。

**** bioProcessBackgroundJobs
线程回调函数，从队列中取出job并且执行.我们这里稍微看看如何执行job.
   - 对于CLOSE_FILE的话那么close(arg1).
   - 对于AOF_FSYNC的话那么aof_fsync(arg1).
#+BEGIN_SRC C++
        /* Process the job accordingly to its type. */
        if (type == REDIS_BIO_CLOSE_FILE) {
            close((long)job->arg1);
        } else if (type == REDIS_BIO_AOF_FSYNC) {
            aof_fsync((long)job->arg1);
        } else {
            redisPanic("Wrong job type in bioProcessBackgroundJobs().");
        }
#+END_SRC

*** AOF
AOF引入是redis为了通过log方式做持久化.

**** Interface
#+BEGIN_SRC C++
// redis.h
/* Append only defines */
#define APPENDFSYNC_NO 0
#define APPENDFSYNC_ALWAYS 1
#define APPENDFSYNC_EVERYSEC 2

/* AOF persistence */
void flushAppendOnlyFile(int force); // flush AOF.
void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc); // 追加记录.
void aofRemoveTempFile(pid_t childpid);
int rewriteAppendOnlyFileBackground(void);
int loadAppendOnlyFile(char *filename); // load AOF.
void stopAppendOnly(void); // stop AOF.
int startAppendOnly(void); // start AOF.
void backgroundRewriteDoneHandler(int statloc); // rewrite done的回调.
#+END_SRC

**** flushAppendOnlyFile
策略比较复杂。我觉得还是仔细分析一下代码会比较好。
#+BEGIN_SRC C++
/* Write the append only file buffer on disk.
 *
 * Since we are required to write the AOF before replying to the client,
 * and the only way the client socket can get a write is entering when the
 * the event loop, we accumulate all the AOF writes in a memory
 * buffer and write it on disk using this function just before entering
 * the event loop again.
 *
 * About the 'force' argument:
 *
 * When the fsync policy is set to 'everysec' we may delay the flush if there
 * is still an fsync() going on in the background thread, since for instance
 * on Linux write(2) will be blocked by the background fsync anyway.
 * When this happens we remember that there is some aof buffer to be
 * flushed ASAP, and will try to do that in the serverCron() function.
 *
 * However if force is set to 1 we'll write regardless of the background
 * fsync. */
void flushAppendOnlyFile(int force) {
    ssize_t nwritten;
    int sync_in_progress = 0;

    // 如果没有任何aof内容的话.
    if (sdslen(server.aofbuf) == 0) return;

    // 后台是否有fsync任务.
    if (server.appendfsync == APPENDFSYNC_EVERYSEC)
        sync_in_progress = bioPendingJobsOfType(REDIS_BIO_AOF_FSYNC) != 0;

    // 如果不强制刷新的话.
    if (server.appendfsync == APPENDFSYNC_EVERYSEC && !force) {
        /* With this append fsync policy we do background fsyncing.
         * If the fsync is still in progress we can try to delay
         * the write for a couple of seconds. */
        if (sync_in_progress) { // 但是后台有任务的话.
            if (server.aof_flush_postponed_start == 0) {
                /* No previous write postponinig, remember that we are
                 * postponing the flush and return. */
                server.aof_flush_postponed_start = server.unixtime;
                return;
            } else if (server.unixtime - server.aof_flush_postponed_start < 2) {
                /* We were already waiting for fsync to finish, but for less
                 * than two seconds this is still ok. Postpone again. */
                return;
            }
            // 但是2s没有刷新下去的话那么会报警.
            /* Otherwise fall trough, and go write since we can't wait
             * over two seconds. */
            redisLog(REDIS_NOTICE,"Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.");
        }
    }
    /* If you are following this code path, then we are going to write so
     * set reset the postponed flush sentinel to zero. */
    server.aof_flush_postponed_start = 0;

     // 同步写入内容.写文件这些内容肯定会写入.
    /* We want to perform a single write. This should be guaranteed atomic
     * at least if the filesystem we are writing is a real physical one.
     * While this will save us against the server being killed I don't think
     * there is much to do about the whole server stopping for power problems
     * or alike */
    nwritten = write(server.appendfd,server.aofbuf,sdslen(server.aofbuf));
    if (nwritten != (signed)sdslen(server.aofbuf)) {
        /* Ooops, we are in troubles. The best thing to do for now is
         * aborting instead of giving the illusion that everything is
         * working as expected. */
        if (nwritten == -1) {
            redisLog(REDIS_WARNING,"Exiting on error writing to the append-only file: %s",strerror(errno));
        } else {
            redisLog(REDIS_WARNING,"Exiting on short write while writing to the append-only file: %s",strerror(errno));
        }
        exit(1);
    }
    server.appendonly_current_size += nwritten;

    // 考虑是否需要释放原来内存.
    /* Re-use AOF buffer when it is small enough. The maximum comes from the
     * arena size of 4k minus some overhead (but is otherwise arbitrary). */
    if ((sdslen(server.aofbuf)+sdsavail(server.aofbuf)) < 4000) {
        sdsclear(server.aofbuf);
    } else {
        sdsfree(server.aofbuf);
        server.aofbuf = sdsempty();
    }

    // 如果后台有rewrite的话那么考虑是否需要fsync.
    /* Don't fsync if no-appendfsync-on-rewrite is set to yes and there are
     * children doing I/O in the background. */
    if (server.no_appendfsync_on_rewrite &&
        (server.bgrewritechildpid != -1 || server.bgsavechildpid != -1))
            return;

    // 更新fsync时间.
    /* Perform the fsync if needed. */
    if (server.appendfsync == APPENDFSYNC_ALWAYS) {
        /* aof_fsync is defined as fdatasync() for Linux in order to avoid
         * flushing metadata. */
        aof_fsync(server.appendfd); /* Let's try to get this data on the disk */
        server.lastfsync = server.unixtime;
    } else if ((server.appendfsync == APPENDFSYNC_EVERYSEC &&
                server.unixtime > server.lastfsync)) {
        if (!sync_in_progress) aof_background_fsync(server.appendfd);
        server.lastfsync = server.unixtime;
    }
}
#+END_SRC

**** stopAppendOnly
停止AOF功能.同时需要停止后台rewrite过程.
#+BEGIN_SRC C++
/* Called when the user switches from "appendonly yes" to "appendonly no"
 * at runtime using the CONFIG command. */
void stopAppendOnly(void) {
    flushAppendOnlyFile(1);
    aof_fsync(server.appendfd);
    close(server.appendfd);

    server.appendfd = -1;
    server.appendseldb = -1;
    server.appendonly = 0;
    /* rewrite operation in progress? kill it, wait child exit */
    if (server.bgrewritechildpid != -1) {
        int statloc;

        if (kill(server.bgrewritechildpid,SIGKILL) != -1)
            wait3(&statloc,0,NULL);
        /* reset the buffer accumulating changes while the child saves */
        sdsfree(server.bgrewritebuf);
        server.bgrewritebuf = sdsempty();
        server.bgrewritechildpid = -1;
    }
}
#+END_SRC

**** startAppendOnly
开启AOF功能.
#+BEGIN_SRC C++
/* Called when the user switches from "appendonly no" to "appendonly yes"
 * at runtime using the CONFIG command. */
int startAppendOnly(void) {
    server.appendonly = 1;
    server.lastfsync = time(NULL); // 刚开启的话必然已经调用了fsync.
    server.appendfd = open(server.appendfilename,O_WRONLY|O_APPEND|O_CREAT,0644);
    if (server.appendfd == -1) {
        redisLog(REDIS_WARNING,"Used tried to switch on AOF via CONFIG, but I can't open the AOF file: %s",strerror(errno));
        return REDIS_ERR;
    }
    if (rewriteAppendOnlyFileBackground() == REDIS_ERR) { // 后台启动AOF以及rewrite工作.
        server.appendonly = 0;
        close(server.appendfd);
        redisLog(REDIS_WARNING,"Used tried to switch on AOF via CONFIG, I can't trigger a background AOF rewrite operation. Check the above logs for more info about the error.",strerror(errno));
        return REDIS_ERR;
    }
    return REDIS_OK;
}
#+END_SRC

**** rewriteAppendOnlyFileBackground
TODO(dirlt):

*** Memory Management
redis对malloc进行了包装，在zmalloc.h下面。redis自带了jemalloc.代码内部的话允许使用jemalloc,tcmalloc以及glibc malloc.

**** defines
如果没有提供malloc_size这种接口的话，那么我们需要自己在头部追加部分。追加大小叫做PREFIX_SIZE.
#+BEGIN_SRC C++
#ifdef HAVE_MALLOC_SIZE
#define PREFIX_SIZE (0)
#else
#if defined(__sun) || defined(__sparc) || defined(__sparc__)
#define PREFIX_SIZE (sizeof(long long))
#else
#define PREFIX_SIZE (sizeof(size_t)) // 对于linux而言的话是size_t.
#endif
#endif
#+END_SRC

对于tcmalloc以及jemalloc进行封装.统一malloc/free等接口.
#+BEGIN_SRC C++
/* Explicitly override malloc/free etc when using tcmalloc. */
#if defined(USE_TCMALLOC)
#define malloc(size) tc_malloc(size)
#define calloc(count,size) tc_calloc(count,size)
#define realloc(ptr,size) tc_realloc(ptr,size)
#define free(ptr) tc_free(ptr)
#elif defined(USE_JEMALLOC)
#define malloc(size) je_malloc(size)
#define calloc(count,size) je_calloc(count,size)
#define realloc(ptr,size) je_realloc(ptr,size)
#define free(ptr) je_free(ptr)
#endif
#+END_SRC

**** Portability
#+BEGIN_SRC C++
/* Double expansion needed for stringification of macro values. */
#define __xstr(s) __str(s)
#define __str(s) #s

#if defined(USE_TCMALLOC)
// 配上tcmalloc的版本.
#define ZMALLOC_LIB ("tcmalloc-" __xstr(TC_VERSION_MAJOR) "." __xstr(TC_VERSION_MINOR))
#include <google/tcmalloc.h>
// 1.6以后开始有zmalloc_size实现.
#if TC_VERSION_MAJOR >= 1 && TC_VERSION_MINOR >= 6
#define HAVE_MALLOC_SIZE 1
#define zmalloc_size(p) tc_malloc_size(p)
#else
#error "Newer version of tcmalloc required"
#endif

#elif defined(USE_JEMALLOC)
// 配上jemalloc版本.
#define ZMALLOC_LIB ("jemalloc-" __xstr(JEMALLOC_VERSION_MAJOR) "." __xstr(JEMALLOC_VERSION_MINOR) "." __xstr(JEMALLOC_VERSION_BUGFIX))
#define JEMALLOC_MANGLE
#include <jemalloc/jemalloc.h>
#if JEMALLOC_VERSION_MAJOR >= 2 && JEMALLOC_VERSION_MINOR >= 1
// 2.1以后开始有zmalloc_size实现.
#define HAVE_MALLOC_SIZE 1
#define zmalloc_size(p) JEMALLOC_P(malloc_usable_size)(p)
#else
#error "Newer version of jemalloc required"
#endif

// 在apple上运行.
#elif defined(__APPLE__)
#include <malloc/malloc.h>
#define HAVE_MALLOC_SIZE 1
#define zmalloc_size(p) malloc_size(p)
#endif

// 如果没有的话那么默认使用libc malloc.
#ifndef ZMALLOC_LIB
#define ZMALLOC_LIB "libc"
#endif
#+END_SRC

**** Interface
#+BEGIN_SRC C++
void *zmalloc(size_t size);
void *zcalloc(size_t size);
void *zrealloc(void *ptr, size_t size);
void zfree(void *ptr);
char *zstrdup(const char *s);
size_t zmalloc_used_memory(void); // 当前分配了多少内存.
void zmalloc_enable_thread_safeness(void); // 确保线程安全.(应该是针对内存统计需要线程安全).
float zmalloc_get_fragmentation_ratio(void); // 碎片率.
size_t zmalloc_get_rss(void); // 实际使用内存.

#ifndef HAVE_MALLOC_SIZE // 如果没有定义这个宏，那么自己来实现
// 这样的话底层实现那么需要空出几个字节来单独表示.
// 不过事实上glibc malloc的dlmalloc应该是有这个接口的。
size_t zmalloc_size(void *ptr);
#endif
#+END_SRC

**** memory stat
主要就是used_memory(使用内存量).然后有一个内存安全选项以及一个互斥锁。
#+BEGIN_SRC C++
static size_t used_memory = 0;
static int zmalloc_thread_safe = 0;
// 互斥锁用来互斥地修改used_memory.
pthread_mutex_t used_memory_mutex = PTHREAD_MUTEX_INITIALIZER;
void zmalloc_enable_thread_safeness(void) {
    zmalloc_thread_safe = 1;
}

// 对于内存统计的更新.如果开启线程安全选项的话那么就需要使用互斥锁进行互斥。
// 注意如果这里分配n个字节的话，计算出来是按照long来进行对齐的。忽略了__size这个参数。
#define update_zmalloc_stat_alloc(__n,__size) do { \
    size_t _n = (__n); \
    if (_n&(sizeof(long)-1)) _n += sizeof(long)-(_n&(sizeof(long)-1)); \
    if (zmalloc_thread_safe) { \
        pthread_mutex_lock(&used_memory_mutex);  \
        used_memory += _n; \
        pthread_mutex_unlock(&used_memory_mutex); \
    } else { \
        used_memory += _n; \
    } \
} while(0)

#define update_zmalloc_stat_free(__n) do { \
    size_t _n = (__n); \
    if (_n&(sizeof(long)-1)) _n += sizeof(long)-(_n&(sizeof(long)-1)); \
    if (zmalloc_thread_safe) { \
        pthread_mutex_lock(&used_memory_mutex);  \
        used_memory -= _n; \
        pthread_mutex_unlock(&used_memory_mutex); \
    } else { \
        used_memory -= _n; \
    } \
} while(0)

size_t zmalloc_used_memory(void) {
    size_t um;

    if (zmalloc_thread_safe) pthread_mutex_lock(&used_memory_mutex);
    um = used_memory;
    if (zmalloc_thread_safe) pthread_mutex_unlock(&used_memory_mutex);
    return um;
}
#+END_SRC

**** zmalloc_oom
内存分配失败的话那么直接退出。
#+BEGIN_SRC C++
static void zmalloc_oom(size_t size) {
    fprintf(stderr, "zmalloc: Out of memory trying to allocate %zu bytes\n",
        size);
    fflush(stderr);
    abort();
}
#+END_SRC

**** zmalloc
这里注意需要多分配PREFIX_SIZE字节，这样可以通过指针来知道分配释放了多少内存。
对于jemalloc以及tcmalloc本身是内置了这个功能的所以PREFIX_SIZE==0.
#+BEGIN_SRC C++
void *zmalloc(size_t size) {
    void *ptr = malloc(size+PREFIX_SIZE);

    if (!ptr) zmalloc_oom(size);
#ifdef HAVE_MALLOC_SIZE
    update_zmalloc_stat_alloc(zmalloc_size(ptr),size);
    return ptr;
#else
    *((size_t*)ptr) = size;
    update_zmalloc_stat_alloc(size+PREFIX_SIZE,size);
    return (char*)ptr+PREFIX_SIZE;
#endif
}
#+END_SRC

**** zcalloc
对于zcalloc代码是类似的.
#+BEGIN_SRC C++
void *zcalloc(size_t size) {
    void *ptr = calloc(1, size+PREFIX_SIZE);

    if (!ptr) zmalloc_oom(size);
#ifdef HAVE_MALLOC_SIZE
    update_zmalloc_stat_alloc(zmalloc_size(ptr),size);
    return ptr;
#else
    *((size_t*)ptr) = size;
    update_zmalloc_stat_alloc(size+PREFIX_SIZE,size);
    return (char*)ptr+PREFIX_SIZE;
#endif
}
#+END_SRC

**** zrealloc
对于zrealloc来说的话过程就稍微繁琐一些。对于zrealloc来说没有判断大小是否变大还是变小，
底层统一交给realloc来处理。也判断了ptr==NULL这个情况。
#+BEGIN_SRC C++
void *zrealloc(void *ptr, size_t size) {
#ifndef HAVE_MALLOC_SIZE
    void *realptr; // 原来真实的指针.
#endif
    size_t oldsize;
    void *newptr;

    if (ptr == NULL) return zmalloc(size);
#ifdef HAVE_MALLOC_SIZE
    oldsize = zmalloc_size(ptr);
    newptr = realloc(ptr,size);
    if (!newptr) zmalloc_oom(size);

    update_zmalloc_stat_free(oldsize);
    update_zmalloc_stat_alloc(zmalloc_size(newptr),size);
    return newptr;
#else
    realptr = (char*)ptr-PREFIX_SIZE;
    oldsize = *((size_t*)realptr);
    newptr = realloc(realptr,size+PREFIX_SIZE);
    if (!newptr) zmalloc_oom(size);

    *((size_t*)newptr) = size;
    update_zmalloc_stat_free(oldsize);
    update_zmalloc_stat_alloc(size,size);
    return (char*)newptr+PREFIX_SIZE;
#endif
}
#+END_SRC

**** zmalloc_size
注意这里zmalloc_size并不是要得到实际上底层mm分配的内存大小，可能想知道两者其一
   - 调用zmalloc时候分配大小.
   - 当时调用zmalloc时候分配大小.
#+BEGIN_SRC C++
/* Provide zmalloc_size() for systems where this function is not provided by
 * malloc itself, given that in that case we store an header with this
 * information as the first bytes of every allocation. */
#ifndef HAVE_MALLOC_SIZE
size_t zmalloc_size(void *ptr) {
    void *realptr = (char*)ptr-PREFIX_SIZE;
    size_t size = *((size_t*)realptr);
    /* Assume at least that all the allocations are padded at sizeof(long) by
     * the underlying allocator. */
    if (size&(sizeof(long)-1)) size += sizeof(long)-(size&(sizeof(long)-1));
    return size+PREFIX_SIZE;
}
#endif
#+END_SRC
但是似乎不管是两者意图的话，上面代码都是不正确的。TODO(dirlt):搞清楚zmalloc_size返回的具体是什么数值。

**** zfree
#+BEGIN_SRC C++
void zfree(void *ptr) {
#ifndef HAVE_MALLOC_SIZE
    void *realptr;
    size_t oldsize;
#endif

    if (ptr == NULL) return;
#ifdef HAVE_MALLOC_SIZE
    update_zmalloc_stat_free(zmalloc_size(ptr));
    free(ptr);
#else
    realptr = (char*)ptr-PREFIX_SIZE; // 得到真实地址然后释放
    oldsize = *((size_t*)realptr);
    update_zmalloc_stat_free(oldsize+PREFIX_SIZE);
    free(realptr);
#endif
}
#+END_SRC

**** zmalloc_get_rss
得到rss信息本身就是一个OS相关的行为，这里我们只是看看linux有/proc文件系统的方式即可.
然后稍微注意一下redis这里的注释。这个函数开销还是比较大的，如果需要快速返回的话可以使用
RedisEstimateRSS这个函数得到大概的估值。
#+BEGIN_SRC C++
/* Get the RSS information in an OS-specific way.
 *
 * WARNING: the function zmalloc_get_rss() is not designed to be fast
 * and may not be called in the busy loops where Redis tries to release
 * memory expiring or swapping out objects.
 *
 * For this kind of "fast RSS reporting" usages use instead the
 * function RedisEstimateRSS() that is a much faster (and less precise)
 * version of the funciton. */

size_t zmalloc_get_rss(void) {
    int page = sysconf(_SC_PAGESIZE);
    size_t rss;
    char buf[4096];
    char filename[256];
    int fd, count;
    char *p, *x;

    snprintf(filename,256,"/proc/%d/stat",getpid());
    if ((fd = open(filename,O_RDONLY)) == -1) return 0;
    if (read(fd,buf,4096) <= 0) {
        close(fd);
        return 0;
    }
    close(fd);

    p = buf;
    count = 23; /* RSS is the 24th field in /proc/<pid>/stat */
    while(p && count--) {
        p = strchr(p,' ');
        if (p) p++;
    }
    if (!p) return 0;
    x = strchr(p,' ');
    if (!x) return 0;
    *x = '\0';

    rss = strtoll(p,NULL,10);
    rss *= page;
    return rss;
}
#+END_SRC

**** zmalloc_get_fragmentation_ratio
注意这个并不是我们传统意义上面的碎片率，我们在实际解读这个数值的时候必须和传统意义"碎片率"区分开。
#+BEGIN_SRC C++
/* Fragmentation = RSS / allocated-bytes */
float zmalloc_get_fragmentation_ratio(void) {
    return (float)zmalloc_get_rss()/zmalloc_used_memory();
}
#+END_SRC

*** Data Structure
**** adlist
A generic doubly linked list implementation.通用双向链表实现(adlist.h).
实现看上去非常简单，非线程安全。这里就不进行更多分析。
#+BEGIN_SRC C++
typedef struct listNode {
    struct listNode *prev;
    struct listNode *next;
    void *value; // 内容.
} listNode;

typedef struct listIter {
    listNode *next; // 当前节点.
    int direction; // 迭代器方向.
} listIter;

/* Directions for iterators */
#define AL_START_HEAD 0
#define AL_START_TAIL 1

typedef struct list {
    listNode *head; // head.
    listNode *tail; // tail.
    void *(*dup)(void *ptr); // 复制对象.
    void (*free)(void *ptr); // 释放对象.可以使用引用计数释放对象
    int (*match)(void *ptr, void *key); // 比较对象.
    unsigned int len; // 长度.
} list;
#+END_SRC

**** intset
intset实现std::set<int>这样的效果。内部存储的话采用二分方式。稍微看了一下使用场景，
redis针对这种小批量存储的话使用这种特殊结构，如果过大的话那么可以转换称为hashtable或者是skiplist
这种通用的结构。intset如果数据量过大的话那么可以转换称为hashtable这种结构。里面实现非常精彩.

***** Interface
intset内部二进制存储是有序的所以在查找时候可以通过二分查找完成。intset量不会非常大，
二分查找非常快，同时维护这个结构可能需要整体移动部分也不会太损效率。
#+BEGIN_SRC C++
typedef struct intset {
    uint32_t encoding; // 编码方式.这个在实现时候会理解是什么意思.
    uint32_t length; // 存储的int的个数.
    int8_t contents[]; // 存储的二进制表示.
} intset;

intset *intsetNew(void);
intset *intsetAdd(intset *is, int64_t value, uint8_t *success);
intset *intsetRemove(intset *is, int64_t value, int *success);
uint8_t intsetFind(intset *is, int64_t value);
int64_t intsetRandom(intset *is);
uint8_t intsetGet(intset *is, uint32_t pos, int64_t *value);
uint32_t intsetLen(intset *is);
size_t intsetBlobLen(intset *is);
#+END_SRC

***** Encoding
intset内部有三种encodings.存储上的话都是按照某种encoding存储的，所以可以认为是同构的。
当插入某个值的时候，redis会自动判断应该采用什么encoding.
#+BEGIN_SRC C++
/* Note that these encodings are ordered, so:
 * INTSET_ENC_INT16 < INTSET_ENC_INT32 < INTSET_ENC_INT64. */
#define INTSET_ENC_INT16 (sizeof(int16_t))
#define INTSET_ENC_INT32 (sizeof(int32_t))
#define INTSET_ENC_INT64 (sizeof(int64_t))
#+END_SRC
加入encoding是INTSET_ENC_INT16的话，那么contents里面每个单元都是int16_t来存储的.

***** _intsetValueEncoding
redis根据value自动检测采用什么encoding.
#+BEGIN_SRC C++
/* Return the required encoding for the provided value. */
static uint8_t _intsetValueEncoding(int64_t v) {
    if (v < INT32_MIN || v > INT32_MAX)
        return INTSET_ENC_INT64;
    else if (v < INT16_MIN || v > INT16_MAX)
        return INTSET_ENC_INT32;
    else
        return INTSET_ENC_INT16;
}
#+END_SRC

***** _intsetGet
提供position以及对应的encoding,得到这个position上面存储的数值.内部存储都是按照little endian来完成的。
#+BEGIN_SRC C++
/* Return the value at pos, given an encoding. */
static int64_t _intsetGetEncoded(intset *is, int pos, uint8_t enc) {
    int64_t v64;
    int32_t v32;
    int16_t v16;

    if (enc == INTSET_ENC_INT64) {
        memcpy(&v64,((int64_t*)is->contents)+pos,sizeof(v64));
        memrev64ifbe(&v64);
        return v64;
    } else if (enc == INTSET_ENC_INT32) {
        memcpy(&v32,((int32_t*)is->contents)+pos,sizeof(v32));
        memrev32ifbe(&v32);
        return v32;
    } else {
        memcpy(&v16,((int16_t*)is->contents)+pos,sizeof(v16));
        memrev16ifbe(&v16);
        return v16;
    }
}

/* Return the value at pos, using the configured encoding. */
static int64_t _intsetGet(intset *is, int pos) {
    return _intsetGetEncoded(is,pos,is->encoding);
}
#+END_SRC

***** _intsetSet
将value按照某个encoding插入到position位置.应该是底层的方法.注意set的时候的话底层也会转换称为little endian.
#+BEGIN_SRC C++
/* Set the value at pos, using the configured encoding. */
static void _intsetSet(intset *is, int pos, int64_t value) {
    if (is->encoding == INTSET_ENC_INT64) {
        ((int64_t*)is->contents)[pos] = value;
        memrev64ifbe(((int64_t*)is->contents)+pos);
    } else if (is->encoding == INTSET_ENC_INT32) {
        ((int32_t*)is->contents)[pos] = value;
        memrev32ifbe(((int32_t*)is->contents)+pos);
    } else {
        ((int16_t*)is->contents)[pos] = value;
        memrev16ifbe(((int16_t*)is->contents)+pos);
    }
}
#+END_SRC

***** intsetNew
创建intset对象.初始话时候按照最小的encoding来创建.
#+BEGIN_SRC C++
/* Create an empty intset. */
intset *intsetNew(void) {
    intset *is = zmalloc(sizeof(intset));
    is->encoding = INTSET_ENC_INT16;
    is->length = 0;
    return is;
}
#+END_SRC

***** intsetResize
对intset的连续内存进行扩展至size.
#+BEGIN_SRC C++
/* Resize the intset */
static intset *intsetResize(intset *is, uint32_t len) {
    uint32_t size = len*is->encoding;
    is = zrealloc(is,sizeof(intset)+size);
    return is;
}
#+END_SRC

***** intsetSearch
在intset里面找到value对应的position.如果OK的话那么返回1,否则返回0.内部采用的二分算法来进行查找.
如果return 0的话返回的是可以插入的位置。
#+BEGIN_SRC C++
/* Search for the position of "value". Return 1 when the value was found and
 * sets "pos" to the position of the value within the intset. Return 0 when
 * the value is not present in the intset and sets "pos" to the position
 * where "value" can be inserted. */
static uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) {
    int min = 0, max = is->length-1, mid = -1;
    int64_t cur = -1;

    /* The value can never be found when the set is empty */
    if (is->length == 0) {
        if (pos) *pos = 0;
        return 0;
    } else {
        /* Check for the case where we know we cannot find the value,
         * but do know the insert position. */
        if (value > _intsetGet(is,is->length-1)) { // 判断一下两个极限情况.
            if (pos) *pos = is->length;
            return 0;
        } else if (value < _intsetGet(is,0)) {
            if (pos) *pos = 0;
            return 0;
        }
    }

    while(max >= min) {
        mid = (min+max)/2;
        cur = _intsetGet(is,mid);
        if (value > cur) {
            min = mid+1;
        } else if (value < cur) {
            max = mid-1;
        } else {
            break;
        }
    }

    if (value == cur) {
        if (pos) *pos = mid;
        return 1;
    } else {
        if (pos) *pos = min;
        return 0;
    }
}
#+END_SRC

***** intsetUpgradeAndAdd
按照新的encoding重写并且添加新元素。这里之所以可以直接判断value<0的原因很简单。
因为value导致整个encoding变大，
   - 如果value<0的话，那么说明比原来任何值都小.
   - 如果value>0的话，那么说明比原来任何值都要大。
#+BEGIN_SRC C++
/* Upgrades the intset to a larger encoding and inserts the given integer. */
static intset *intsetUpgradeAndAdd(intset *is, int64_t value) {
    uint8_t curenc = is->encoding;
    uint8_t newenc = _intsetValueEncoding(value);
    int length = is->length;
    int prepend = value < 0 ? 1 : 0; // 判断是应该放在最前面还是最后面.

    /* First set new encoding and resize */
    is->encoding = newenc;
    is = intsetResize(is,is->length+1);

    /* Upgrade back-to-front so we don't overwrite values.
     * Note that the "prepend" variable is used to make sure we have an empty
     * space at either the beginning or the end of the intset. */
    while(length--) // 这里需要重新计算一次encoding.
        _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc));

    /* Set the value at the beginning or the end. */
    if (prepend) // 然后决定这个value是放在后面还是前面.
        _intsetSet(is,0,value);
    else
        _intsetSet(is,is->length,value);
    is->length++;
    return is;
}
#+END_SRC

***** intsetMoveTail
movetail这个名字似乎比较有歧义，更准确的意思应该就是memove但是不改变encoding.
因为这个时候仅仅是需要加入一个value所以intset需要腾出一个位置出来.
#+BEGIN_SRC C++
static void intsetMoveTail(intset *is, uint32_t from, uint32_t to) {
    void *src, *dst;
    uint32_t bytes = is->length-from;
    if (is->encoding == INTSET_ENC_INT64) {
        src = (int64_t*)is->contents+from;
        dst = (int64_t*)is->contents+to;
        bytes *= sizeof(int64_t);
    } else if (is->encoding == INTSET_ENC_INT32) {
        src = (int32_t*)is->contents+from;
        dst = (int32_t*)is->contents+to;
        bytes *= sizeof(int32_t);
    } else {
        src = (int16_t*)is->contents+from;
        dst = (int16_t*)is->contents+to;
        bytes *= sizeof(int16_t);
    }
    memmove(dst,src,bytes);
}
#+END_SRC

***** intsetAdd
TODO(dirlt):

***** intsetRemove
TODO(dirlt):

***** intsetFind
TODO(dirlt):

***** intsetRandom
TODO(dirlt):

***** intsetGet
TODO(dirlt):

***** intsetLen
TODO(dirlt):

***** intsetBlobLen
TODO(dirlt):

**** dict
dict本质实现上是hashtable.dict实现得非常通用。个人感觉非常精巧所以非常想读一读。
实现了iterator(虽然同样很有局限性)和rehash(step rehash以及超时rehash策略让我学到很多东西).

***** structs
#+BEGIN_SRC C++
#define DICT_OK 0
#define DICT_ERR 1

/* Unused arguments generate annoying warnings... */
// 这个宏非常有意思的。在redis里面很多地方可以看到这个宏使用
// 解决的问题就是在一个函数里面如果不使用某个参数的话，如果gcc -W -Wall会报告unused parameter警告
// 这样我们可以在这个地方使用DICT_NOTUSED(v)来消除这个警告.
#define DICT_NOTUSED(V) ((void) V)

typedef struct dictEntry { // 每个hash item的entry.存在kv以及next指针来做外链冲突处理。
    void *key;
    void *val;
    struct dictEntry *next;
} dictEntry;

typedef struct dictType { // 字典类型.里面提供了相当多的策略来决定如何进行hash以及kv如何copy.
    unsigned int (*hashFunction)(const void *key);
    void *(*keyDup)(void *privdata, const void *key);
    void *(*valDup)(void *privdata, const void *obj);
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);
    void (*keyDestructor)(void *privdata, void *key);
    void (*valDestructor)(void *privdata, void *obj);
} dictType;

/* This is our hash table structure. Every dictionary has two of this as we
 * implement incremental rehashing, for the old to the new table. */
typedef struct dictht { // 字典table.
    dictEntry **table;
    unsigned long size; // hashtable多少个槽位.2^n
    unsigned long sizemask; // 快速地计算hash code.(2^n-1).
    unsigned long used; // 里面存放了多少个元素
} dictht;

typedef struct dict { // 字典是两个hashtable可以进行rehash操作.
    dictType *type;
    void *privdata; // private data.
    dictht ht[2]; // 两个hashtable更换使用.
    // 如果==-1表示当前没有rehash.
    // 否则表示当前rehash到第几个slot.
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */
    int iterators; /* number of iterators currently running */ // 当前作用在这个dict上面iterator个数.
} dict;

/* If safe is set to 1 this is a safe iteartor, that means, you can call
 * dictAdd, dictFind, and other functions against the dictionary even while
 * iterating. Otherwise it is a non safe iterator, and only dictNext()
 * should be called while iterating. */
typedef struct dictIterator {
    dict *d;
    int table, index, safe; // 当前在第几个table并且index是多少.
    // 关于safe字段的话在注释上面有解释.
    dictEntry *entry, *nextEntry;
} dictIterator;

/* This is the initial size of every hash table */
#define DICT_HT_INITIAL_SIZE     4 // 初始化的时候大小是4.

#+END_SRC

***** defines
#+BEGIN_SRC C++
/* ------------------------------- Macros ------------------------------------*/
#define dictFreeEntryVal(d, entry) \
    if ((d)->type->valDestructor) \
        (d)->type->valDestructor((d)->privdata, (entry)->val)

// 设置value的话如果存在duplicate函数的话那么就会调用.
#define dictSetHashVal(d, entry, _val_) do { \
    if ((d)->type->valDup) \
        entry->val = (d)->type->valDup((d)->privdata, _val_); \
    else \
        entry->val = (_val_); \
} while(0)

#define dictFreeEntryKey(d, entry) \
    if ((d)->type->keyDestructor) \
        (d)->type->keyDestructor((d)->privdata, (entry)->key)

// 设置key和设置value是一样的，如果存在key duplicate函数.
#define dictSetHashKey(d, entry, _key_) do { \
    if ((d)->type->keyDup) \
        entry->key = (d)->type->keyDup((d)->privdata, _key_); \
    else \
        entry->key = (_key_); \
} while(0)

// 如果没有设置key compare函数的话那么直接比较指针是否相同.
#define dictCompareHashKeys(d, key1, key2) \
    (((d)->type->keyCompare) ? \
        (d)->type->keyCompare((d)->privdata, key1, key2) : \
        (key1) == (key2))

// 计算key的hash值.
#define dictHashKey(d, key) (d)->type->hashFunction(key)

#define dictGetEntryKey(he) ((he)->key)
#define dictGetEntryVal(he) ((he)->val)
// 提供了多少个hash槽位
#define dictSlots(d) ((d)->ht[0].size+(d)->ht[1].size)
// 占用了hashtable多少个item
#define dictSize(d) ((d)->ht[0].used+(d)->ht[1].used)
// 当前是否正在进行rehash.
#define dictIsRehashing(ht) ((ht)->rehashidx != -1)
#+END_SRC

***** Interface
对于这种hashtable的实现，因为之前没有接触过rehash这样的实现并且配合了hashtable的迭代器，
所以比较想看看redis的hashtable是如何实现的。首先看看redis提供的hashtable接口。
#+BEGIN_SRC C++
/* API */
dict *dictCreate(dictType *type, void *privDataPtr);
int dictExpand(dict *d, unsigned long size);
int dictAdd(dict *d, void *key, void *val);
int dictReplace(dict *d, void *key, void *val);
int dictDelete(dict *d, const void *key);
int dictDeleteNoFree(dict *d, const void *key);
void dictRelease(dict *d);
dictEntry * dictFind(dict *d, const void *key);
void *dictFetchValue(dict *d, const void *key);
int dictResize(dict *d);
dictIterator *dictGetIterator(dict *d);
dictIterator *dictGetSafeIterator(dict *d);
dictEntry *dictNext(dictIterator *iter);
void dictReleaseIterator(dictIterator *iter);
dictEntry *dictGetRandomKey(dict *d);
void dictPrintStats(dict *d);
unsigned int dictGenHashFunction(const unsigned char *buf, int len);
unsigned int dictGenCaseHashFunction(const unsigned char *buf, int len);
void dictEmpty(dict *d);
void dictEnableResize(void);
void dictDisableResize(void);
int dictRehash(dict *d, int n);
int dictRehashMilliseconds(dict *d, int ms);

// 最后redis提供了几种默认字典类型.
// 其实这个方式在c里面实现挺不错的。通过将策略单独分离出来
// 可以非常好地简化代码并且容易阅读。
// NOTICE(dirlt):阅读代码后面才发现，这几个dict type仅仅是作为example的
// 在redis内部并没有使用.
/* Hash table types */
extern dictType dictTypeHeapStringCopyKey;
extern dictType dictTypeHeapStrings;
extern dictType dictTypeHeapStringCopyKeyValue;
#+END_SRC

***** DictType
NOTICE(dirlt):阅读完了代码才发现，在dict.c里面给了注释
#+BEGIN_SRC C++
/* The following are just example hash table types implementations.
 * Not useful for Redis so they are commented out.
 */
#+END_SRC
实际上这几个dicttype并没有被redis使用，只不过作为example.

我们看看redis提供的几种dict策略.我们这里稍微整合一下.
   - HashFunction. _dictStringCopyHTHashFunction
   - keyDup NULL(浅拷贝) / _dictStringDup
   - valDup NULL(浅拷贝) / _dictStringDup
   - keyCompare _dictStringCopyHTKeyCompare
   - keyDtor NULL(浅拷贝) / _dictStringDestructor
   - valDtor NULL(浅拷贝) / _dictStringDestructor
#+BEGIN_SRC C++
dictType dictTypeHeapStringCopyKey = {
    _dictStringCopyHTHashFunction, /* hash function */
    _dictStringDup,                /* key dup */
    NULL,                          /* val dup */
    _dictStringCopyHTKeyCompare,   /* key compare */
    _dictStringDestructor,         /* key destructor */
    NULL                           /* val destructor */
};

/* This is like StringCopy but does not auto-duplicate the key.
 * It's used for intepreter's shared strings. */
dictType dictTypeHeapStrings = {
    _dictStringCopyHTHashFunction, /* hash function */
    NULL,                          /* key dup */
    NULL,                          /* val dup */
    _dictStringCopyHTKeyCompare,   /* key compare */
    _dictStringDestructor,         /* key destructor */
    NULL                           /* val destructor */
};

/* This is like StringCopy but also automatically handle dynamic
 * allocated C strings as values. */
dictType dictTypeHeapStringCopyKeyValue = {
    _dictStringCopyHTHashFunction, /* hash function */
    _dictStringDup,                /* key dup */
    _dictStringDup,                /* val dup */
    _dictStringCopyHTKeyCompare,   /* key compare */
    _dictStringDestructor,         /* key destructor */
    _dictStringDestructor,         /* val destructor */
};
#+END_SRC

我们稍微看看涉及到的各个函数实现.具体实现都非常简单，底层底层都是key,value作为string来处理.
#+BEGIN_SRC C++
/* Generic hash function (a popular one from Bernstein).
 * I tested a few and this was the best. */
unsigned int dictGenHashFunction(const unsigned char *buf, int len) {
    unsigned int hash = 5381;

    while (len--)
        hash = ((hash << 5) + hash) + (*buf++); /* hash * 33 + c */
    return hash;
}

static unsigned int _dictStringCopyHTHashFunction(const void *key)
{
    return dictGenHashFunction(key, strlen(key));
}

static void *_dictStringDup(void *privdata, const void *key)
{
    int len = strlen(key);
    char *copy = zmalloc(len+1);
    DICT_NOTUSED(privdata);

    memcpy(copy, key, len);
    copy[len] = '\0';
    return copy;
}

static int _dictStringCopyHTKeyCompare(void *privdata, const void *key1,
        const void *key2)
{
    DICT_NOTUSED(privdata);

    return strcmp(key1, key2) == 0;
}

static void _dictStringDestructor(void *privdata, void *key)
{
    DICT_NOTUSED(privdata);

    zfree(key);
}
#+END_SRC
在dict.c里面提供了几种hash算法.
   - dictIntHashFunction 将int映射称为一个hash code.做了32 bit mix function.
   - dictIdentityHashFunction 直接返回具体的int值.
   - dictGenHashFunction 普通hash算法
   - dictGenCaseHashFunction 不考虑大小写的hash算法.

***** _dictReset
清空dict.这里只是修改指针内容，关于table释放的话在destroy部分就要完成.
#+BEGIN_SRC C++
/* Reset an hashtable already initialized with ht_init().
 * NOTE: This function should only called by ht_destroy(). */
static void _dictReset(dictht *ht)
{
    ht->table = NULL;
    ht->size = 0;
    ht->sizemask = 0;
    ht->used = 0;
}
#+END_SRC

***** _dictInit
初始化dict.设置private data并且设置not rehash状态.
#+BEGIN_SRC C++
/* Initialize the hash table */
int _dictInit(dict *d, dictType *type,
        void *privDataPtr)
{
    _dictReset(&d->ht[0]);
    _dictReset(&d->ht[1]);
    d->type = type;
    d->privdata = privDataPtr;
    d->rehashidx = -1; // 没有进行rehash.
    d->iterators = 0;  // 没有任何迭代器.
    return DICT_OK;
}
#+END_SRC

***** dictCreate
创建dict.注意内部并没有分配任何空间.这样可以加速创建的速度，将分配过程平摊在操作中.
这点在设计时候也是十分合理的，实际上rehash也可以认为是这样的过程.
#+BEGIN_SRC C++
/* Create a new hash table */
dict *dictCreate(dictType *type,
        void *privDataPtr)
{
    dict *d = zmalloc(sizeof(*d));

    _dictInit(d,type,privDataPtr);
    return d;
}
#+END_SRC

***** dictResize
为dict重新分配大小.底层是调用dictExpand指定了希望expand到的大小.
这里涉及到了一个dict_can_resize变量(==1).如果调用函数正在进行rehash的话，那么会失败.
#+BEGIN_SRC C++
/* Resize the table to the minimal size that contains all the elements,
 * but with the invariant of a USER/BUCKETS ratio near to <= 1 */
int dictResize(dict *d)
{
    int minimal;

    if (!dict_can_resize || dictIsRehashing(d)) return DICT_ERR;
    minimal = d->ht[0].used;
    if (minimal < DICT_HT_INITIAL_SIZE)
        minimal = DICT_HT_INITIAL_SIZE;
    return dictExpand(d, minimal);
}
#+END_SRC

***** _dictNextPower
得到第一个比size大的2^(n+2)的数值.主要是为了计算expand之后的hashtable大小.
#+BEGIN_SRC C++
/* Our hash table capability is a power of two */
static unsigned long _dictNextPower(unsigned long size)
{
    unsigned long i = DICT_HT_INITIAL_SIZE; // ==4

    if (size >= LONG_MAX) return LONG_MAX;
    while(1) {
        if (i >= size)
            return i;
        i *= 2;
    }
}
#+END_SRC

***** dictExpand
TODO(dirlt):这个地方似乎没有看懂ht(0)和ht(1)是如何交替使用的.

NOTICE(dirlt):应该是ht(0)和ht(1)个存在一部分数据.然后每次都是从ht(0)->ht(1)移动.
一旦移动完成的话，那么将ht(1)->ht(0)同时清空ht(1).
#+BEGIN_SRC C++
/* Expand or create the hashtable */
int dictExpand(dict *d, unsigned long size)
{
    dictht n; /* the new hashtable */
    unsigned long realsize = _dictNextPower(size); // 分配的hash slot是多少.

    /* the size is invalid if it is smaller than the number of
     * elements already inside the hashtable */
    if (dictIsRehashing(d) || d->ht[0].used > size) //如果正在rehash或者是used个数过多的话.
        return DICT_ERR;

    /* Allocate the new hashtable and initialize all pointers to NULL */
    n.size = realsize;
    n.sizemask = realsize-1;
    n.table = zcalloc(realsize*sizeof(dictEntry*));
    n.used = 0;

    /* Is this the first initialization? If so it's not really a rehashing
     * we just set the first hash table so that it can accept keys. */
    if (d->ht[0].table == NULL) {
        d->ht[0] = n;
        return DICT_OK;
    }

    /* Prepare a second hash table for incremental rehashing */
    d->ht[1] = n;
    d->rehashidx = 0;
    return DICT_OK;
}
#+END_SRC

***** dictRehash
dictRehash是一个增量hash的效果.每次只是rehash其中n个bucket依次来达到增量rehash.非常巧妙.
返回值上面如果==0的话表示rehash完成否则需要继续进行rehash.rehashidx!=-1的话表示当前正在rehash.
不过在rehash算法上面没有非常精巧的地方.
#+BEGIN_SRC C++
/* Performs N steps of incremental rehashing. Returns 1 if there are still
 * keys to move from the old to the new hash table, otherwise 0 is returned.
 * Note that a rehashing step consists in moving a bucket (that may have more
 * thank one key as we use chaining) from the old to the new hash table. */
int dictRehash(dict *d, int n) {
    if (!dictIsRehashing(d)) return 0;

    while(n--) {
        dictEntry *de, *nextde;

        /* Check if we already rehashed the whole table... */
        if (d->ht[0].used == 0) { // 如果ht(0)已经完全被rehash到ht(1)的话
            zfree(d->ht[0].table);
            d->ht[0] = d->ht[1];
            _dictReset(&d->ht[1]);
            d->rehashidx = -1;
            return 0;
        }

        /* Note that rehashidx can't overflow as we are sure there are more
         * elements because ht[0].used != 0 */
        while(d->ht[0].table[d->rehashidx] == NULL) d->rehashidx++;
        de = d->ht[0].table[d->rehashidx];
        /* Move all the keys in this bucket from the old to the new hash HT */
        while(de) {
            unsigned int h;

            nextde = de->next;
            /* Get the index in the new hash table */
            h = dictHashKey(d, de->key) & d->ht[1].sizemask;
            de->next = d->ht[1].table[h];
            d->ht[1].table[h] = de;
            d->ht[0].used--;
            d->ht[1].used++;
            de = nextde;
        }
        d->ht[0].table[d->rehashidx] = NULL;
        d->rehashidx++;
    }
    return 1;
}
#+END_SRC

***** dictRehashMilliseconds
在固定的时间内尽可能多地完成rehash.以此来达到增量rehash过程.非常巧妙.
#+BEGIN_SRC C++
long long timeInMilliseconds(void) {
    struct timeval tv;

    gettimeofday(&tv,NULL);
    return (((long long)tv.tv_sec)*1000)+(tv.tv_usec/1000);
}

/* Rehash for an amount of time between ms milliseconds and ms+1 milliseconds */
// 返回完成了多少个slot的rehash.
int dictRehashMilliseconds(dict *d, int ms) {
    long long start = timeInMilliseconds();
    int rehashes = 0;

    while(dictRehash(d,100)) {
        rehashes += 100;
        if (timeInMilliseconds()-start > ms) break;
    }
    return rehashes;
}
#+END_SRC

***** _dictRehashStep
完成一个bucket的rehash.注释里面说明了触发的时机是在上面没有任何的迭代器，然后在每次update或者是looup
的时候会调用一次.不断地在增量过程中完成rehash过程.
#+BEGIN_SRC C++
/* This function performs just a step of rehashing, and only if there are
 * no safe iterators bound to our hash table. When we have iterators in the
 * middle of a rehashing we can't mess with the two hash tables otherwise
 * some element can be missed or duplicated.
 *
 * This function is called by common lookup or update operations in the
 * dictionary so that the hash table automatically migrates from H1 to H2
 * while it is actively used. */
static void _dictRehashStep(dict *d) {
    if (d->iterators == 0) dictRehash(d,1);
}
#+END_SRC

***** _dictExpandIfNeeded
on demand operation这种操作通常策略是非常重要的。我们来看看这个函数的实现.
#+BEGIN_SRC C++
/* Expand the hash table if needed */
static int _dictExpandIfNeeded(dict *d)
{
    /* Incremental rehashing already in progress. Return. */
    if (dictIsRehashing(d)) return DICT_OK; // 如果正在rehash的话那么没有必要expand.

    /* If the hash table is empty expand it to the intial size. */
    if (d->ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); // size==0说明没有分配
   // 那么尝试分配4个buckets.

    // 如果ratio>=1/1并且
    // 1.dict_can_resize==true
    // 2.或者是ratio > 5(这个比率是在太高了).
    // 那么需要expand.
    // 注意dictExpand的话如果ht(0)!=NULL那么将新的hashtable放在ht(1)
    // 然后开始触发rehash操作.
    /* If we reached the 1:1 ratio, and we are allowed to resize the hash
     * table (global setting) or we should avoid it but the ratio between
     * elements/buckets is over the "safe" threshold, we resize doubling
     * the number of buckets. */
    if (d->ht[0].used >= d->ht[0].size &&
        (dict_can_resize ||
         d->ht[0].used/d->ht[0].size > dict_force_resize_ratio))
    {
        return dictExpand(d, ((d->ht[0].size > d->ht[0].used) ?
                                    d->ht[0].size : d->ht[0].used)*2);
    }
    return DICT_OK;
}
#+END_SRC

***** _dictKeyIndex
根据key找到index.但是同时也会判断这个key是否存在.注意这个函数仅仅是在dictAdd时候调用的。
在dictAdd调用的时候那么就可以考虑进行Expand.所以之前会调用ExpandIfNeeded.
#+BEGIN_SRC C++
/* Returns the index of a free slot that can be populated with
 * an hash entry for the given 'key'.
 * If the key already exists, -1 is returned.
 *
 * Note that if we are in the process of rehashing the hash table, the
 * index is always returned in the context of the second (new) hash table. */
static int _dictKeyIndex(dict *d, const void *key)
{
    unsigned int h, idx, table;
    dictEntry *he;

    /* Expand the hashtable if needed */
    if (_dictExpandIfNeeded(d) == DICT_ERR) // 判断是否有必要expand.
        return -1;
    /* Compute the key hash value */
    h = dictHashKey(d, key);
    for (table = 0; table <= 1; table++) {
        idx = h & d->ht[table].sizemask;
        /* Search if this slot does not already contain the given key */
        he = d->ht[table].table[idx];
        while(he) {
            if (dictCompareHashKeys(d, key, he->key))
                return -1;
            he = he->next;
        }
        if (!dictIsRehashing(d)) break; // 如果没有在rehash的话那么ht(1)是没有必要查找的.
    }
    return idx;
}
#+END_SRC

***** dictAdd
实现过程非常简单。注意里面如果知道在进行rehash的话那么直接插入到ht(1)内部.
#+BEGIN_SRC C++
/* Add an element to the target hash table */
int dictAdd(dict *d, void *key, void *val)
{
    int index;
    dictEntry *entry;
    dictht *ht;

    if (dictIsRehashing(d)) _dictRehashStep(d); // 如果正在进行rehash的话那么会做一个Bucket的rehash.

    /* Get the index of the new element, or -1 if
     * the element already exists. */
    if ((index = _dictKeyIndex(d, key)) == -1) // 找到这个key对应的index.这里会判断key是否已经存在.
        return DICT_ERR;

    /* Allocates the memory and stores key */
    ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0]; // 如果正在rehash的话那么直接放到ht(1)里面.
    entry = zmalloc(sizeof(*entry));
    entry->next = ht->table[index];
    ht->table[index] = entry;
    ht->used++;

    /* Set the hash entry fields. */
    dictSetHashKey(d, entry, key);
    dictSetHashVal(d, entry, val);
    return DICT_OK;
}
#+END_SRC

***** dictReplace
替换kv.逻辑上面是首先尝试添加，如果!OK的话那么找出原来对象出来进行修改.
#+BEGIN_SRC C++
/* Add an element, discarding the old if the key already exists.
 * Return 1 if the key was added from scratch, 0 if there was already an
 * element with such key and dictReplace() just performed a value update
 * operation. */
int dictReplace(dict *d, void *key, void *val)
{
    dictEntry *entry, auxentry;

    /* Try to add the element. If the key
     * does not exists dictAdd will suceed. */
    if (dictAdd(d, key, val) == DICT_OK)
        return 1;
    /* It already exists, get the entry */
    entry = dictFind(d, key);
    /* Free the old value and set the new one */
    /* Set the new value and free the old one. Note that it is important
     * to do that in this order, as the value may just be exactly the same
     * as the previous one. In this context, think to reference counting,
     * you want to increment (set), and then decrement (free), and not the
     * reverse. */
    auxentry = *entry;
    dictSetHashVal(d, entry, val);
    dictFreeEntryVal(d, &auxentry); // 同时释放原来内存.
    return 0;
}
#+END_SRC

***** dictFind
根据k->v.如果没有找到的话那么直接返回NULL.和KeyIndex差别就是这个对于dict来说只是只读操作
不会尝试去修改hashtable做rehash等操作.
#+BEGIN_SRC C++
dictEntry *dictFind(dict *d, const void *key)
{
    dictEntry *he;
    unsigned int h, idx, table;

    if (d->ht[0].size == 0) return NULL; /* We don't have a table at all */
    if (dictIsRehashing(d)) _dictRehashStep(d); // 注意这里也调用了rehash.
    h = dictHashKey(d, key);
    for (table = 0; table <= 1; table++) {
        idx = h & d->ht[table].sizemask;
        he = d->ht[table].table[idx];
        while(he) {
            if (dictCompareHashKeys(d, key, he->key))
                return he;
            he = he->next;
        }
        if (!dictIsRehashing(d)) return NULL; // 同样如果没有在进行rehash操作的时候
       // 是没有必要考虑ht(1)这个hashtable的.
    }
    return NULL;
}

void *dictFetchValue(dict *d, const void *key) {
    dictEntry *he;

    he = dictFind(d,key);
    return he ? dictGetEntryVal(he) : NULL; // 找到对象之后返回里面具体的值.
}
#+END_SRC

***** dictDelete
删除某个item可以决定是否需要进行free.对于dictDelete和dictDeleteNoFree来说底层都是调用dictGenericDelete.
#+BEGIN_SRC C++
/* Search and remove an element */
static int dictGenericDelete(dict *d, const void *key, int nofree)
{
    unsigned int h, idx;
    dictEntry *he, *prevHe;
    int table;

    if (d->ht[0].size == 0) return DICT_ERR; /* d->ht[0].table is NULL */
    if (dictIsRehashing(d)) _dictRehashStep(d); // 注意这里也调用了rehash.
    h = dictHashKey(d, key);

    for (table = 0; table <= 1; table++) {
        idx = h & d->ht[table].sizemask;
        he = d->ht[table].table[idx];
        prevHe = NULL;
        while(he) {
            if (dictCompareHashKeys(d, key, he->key)) {
                /* Unlink the element from the list */
                if (prevHe)
                    prevHe->next = he->next;
                else
                    d->ht[table].table[idx] = he->next;
                if (!nofree) { // 决定是否需要free这个item.
                    dictFreeEntryKey(d, he);
                    dictFreeEntryVal(d, he);
                }
                zfree(he);
                d->ht[table].used--;
                return DICT_OK;
            }
            prevHe = he;
            he = he->next;
        }
        if (!dictIsRehashing(d)) break; // 同样如果正在进行rehash的话
        // 那么可以忽略ht(1)这个hashtable.
    }
    return DICT_ERR; /* not found */
}

int dictDelete(dict *ht, const void *key) {
    return dictGenericDelete(ht,key,0);
}

int dictDeleteNoFree(dict *ht, const void *key) {
    return dictGenericDelete(ht,key,1);
}
#+END_SRC

***** _dictClear
清空dict里面某个hashtable.过程非常简单遍历然后释放key和value.
#+BEGIN_SRC C++
/* Destroy an entire dictionary */
int _dictClear(dict *d, dictht *ht)
{
    unsigned long i;

    /* Free all the elements */
    for (i = 0; i < ht->size && ht->used > 0; i++) {
        dictEntry *he, *nextHe;

        if ((he = ht->table[i]) == NULL) continue;
        while(he) {
            nextHe = he->next;
            dictFreeEntryKey(d, he);
            dictFreeEntryVal(d, he);
            zfree(he);
            ht->used--;
            he = nextHe;
        }
    }
    /* Free the table and the allocated cache structure */
    zfree(ht->table);
    /* Re-initialize the table */
    _dictReset(ht);
    return DICT_OK; /* never fails */
}
#+END_SRC

***** dictRelease
清空ht(0)和ht(1).最终释放这个对象.
#+BEGIN_SRC C++
/* Clear & Release the hash table */
void dictRelease(dict *d)
{
    _dictClear(d,&d->ht[0]);
    _dictClear(d,&d->ht[1]);
    zfree(d);
}
#+END_SRC

***** dictEmpty
和dictRelease不同的是，Empty最后只是将这个dict对象清空(reset).
#+BEGIN_SRC C++
void dictEmpty(dict *d) {
    _dictClear(d,&d->ht[0]);
    _dictClear(d,&d->ht[1]);
    d->rehashidx = -1;
    d->iterators = 0;
}
#+END_SRC

***** dictGetRandomKey
随机地从dict里面选择一个entry出来.不太清楚具体的用途.随机算法写得比较有意思的，
首先针对index做random.然后针对冲突链上面再做一次random.
#+BEGIN_SRC C++
/* Return a random entry from the hash table. Useful to
 * implement randomized algorithms */
dictEntry *dictGetRandomKey(dict *d)
{
    dictEntry *he, *orighe;
    unsigned int h;
    int listlen, listele;

    if (dictSize(d) == 0) return NULL;
    if (dictIsRehashing(d)) _dictRehashStep(d); // 注意这里依然会做一个rehash.
    // 如果是在rehash,那么针对ht(0)和ht(1)做一个随机选择.
    if (dictIsRehashing(d)) {
        do {
            h = random() % (d->ht[0].size+d->ht[1].size);
            he = (h >= d->ht[0].size) ? d->ht[1].table[h - d->ht[0].size] :
                                      d->ht[0].table[h];
        } while(he == NULL);
    } else {
        do {
            h = random() & d->ht[0].sizemask;
            he = d->ht[0].table[h];
        } while(he == NULL);
    }
    // 然后在外链冲突上面做随机选择.
    /* Now we found a non empty bucket, but it is a linked
     * list and we need to get a random element from the list.
     * The only sane way to do so is counting the elements and
     * select a random index. */
    listlen = 0;
    orighe = he;
    while(he) {
        he = he->next;
        listlen++;
    }
    listele = random() % listlen;
    he = orighe;
    while(listele--) he = he->next;
    return he;
}
#+END_SRC

***** dictGetIterator
创建iterator并不是件非常麻烦的事情.对于safe这个字段的含义之前也解释清楚了。
如果safe==0的话那么值允许在上面做一些只读操作比如dictFind和dictNext操作。
但是如果safe==1的话那么允许在上面做一些读写操作比如dictAdd(但是似乎不能够应对dictDelete).

NOTICE(dirlt):阅读rehashstep代码就会发现，如果是safe==1的话那么在dict
上面iterator!=0,这样就不会触发rehash这个操作.
#+BEGIN_SRC C++
dictIterator *dictGetIterator(dict *d)
{
    dictIterator *iter = zmalloc(sizeof(*iter));

    iter->d = d;
    iter->table = 0;
    iter->index = -1;
    iter->safe = 0;
    iter->entry = NULL;
    iter->nextEntry = NULL;
    return iter;
}

dictIterator *dictGetSafeIterator(dict *d) {
    dictIterator *i = dictGetIterator(d);

    i->safe = 1;
    return i;
}
#+END_SRC

***** dictNext
entry和nextEntry字段表示在外链冲突什么位置.table表示在ht(0)和ht(1).index表示在什么bucket上面.
#+BEGIN_SRC C++
dictEntry *dictNext(dictIterator *iter)
{
    while (1) {
        if (iter->entry == NULL) {
            dictht *ht = &iter->d->ht[iter->table];
            if (iter->safe && iter->index == -1 && iter->table == 0)
                iter->d->iterators++;
            iter->index++;
            if (iter->index >= (signed) ht->size) {
                if (dictIsRehashing(iter->d) && iter->table == 0) {
                    iter->table++;
                    iter->index = 0;
                    ht = &iter->d->ht[1];
                } else {
                    break;
                }
            }
            iter->entry = ht->table[iter->index];
        } else {
            iter->entry = iter->nextEntry;
        }
        if (iter->entry) {
            /* We need to save the 'next' here, the iterator user
             * may delete the entry we are returning. */
            iter->nextEntry = iter->entry->next;
            return iter->entry;
        }
    }
    return NULL;
}
#+END_SRC

***** dictReleaseIterator
#+BEGIN_SRC C++
void dictReleaseIterator(dictIterator *iter)
{
    // 如果safe==1并且确实已经调用了Next的话(这样iterators才会计数)
    if (iter->safe && !(iter->index == -1 && iter->table == 0))
        iter->d->iterators--;
    zfree(iter);
}
#+END_SRC

***** dictPrintStats
对于打印每一个hashtable比较琐碎.这里如果发现在rehash的话那么会打印两个hashtable.
#+BEGIN_SRC C++
void dictPrintStats(dict *d) {
    _dictPrintStatsHt(&d->ht[0]);
    if (dictIsRehashing(d)) { // 如果在rehash的话那么会打印ht(1).
        printf("-- Rehashing into ht[1]:\n");
        _dictPrintStatsHt(&d->ht[1]);
    }
}
#+END_SRC

**** ziplist
ziplist是一种内存非常紧凑分配的双向链表，实现起来也非常精彩。假设插入的都是字符串类型，
但是内部的话会尝试将字符串转换称为整数然后存储起来。对于字符串和整数存储的类型也是不尽相同的。
在ziplist.c内部描述了是如何组织的。

***** Format
关于内存组织的话直接看注释就可以了，解释得非常清楚。
   - zlbytes 表示占用了多少个字节
   - zltail 表示末尾entry的offset
   - zllen 表示list共存储了多少个元素
   - entry 每个item
   - zlend 1个字节255.
#+BEGIN_SRC C++
typedef struct zlentry { // 这个应该是内存表示结构而不是最终二进制结构.
    unsigned int prevrawlensize, prevrawlen;
    unsigned int lensize, len;
    unsigned int headersize;
    unsigned char encoding;
    unsigned char *p;
} zlentry;
#+END_SRC
对于每个item而言的话，头部包含了prev item length以及本身这个item的类型以及长度。
关于是如何编码的可以看看下面的注释.对于length编码和zeromq非常相似，而对于item类型和
长度的结合有点类似于UTF8前缀编码
#+BEGIN_SRC C++
/*
 * ZIPLIST OVERALL LAYOUT:
 * The general layout of the ziplist is as follows:
 * <zlbytes><zltail><zllen><entry><entry><zlend>
 *
 * <zlbytes> is an unsigned integer to hold the number of bytes that the
 * ziplist occupies. This value needs to be stored to be able to resize the
 * entire structure without the need to traverse it first.
 *
 * <zltail> is the offset to the last entry in the list. This allows a pop
 * operation on the far side of the list without the need for full traversal.
 *
 * <zllen> is the number of entries.When this value is larger than 2**16-2,
 * we need to traverse the entire list to know how many items it holds.
 *
 * <zlend> is a single byte special value, equal to 255, which indicates the
 * end of the list.
 *
 * ZIPLIST ENTRIES:
 * Every entry in the ziplist is prefixed by a header that contains two pieces
 * of information. First, the length of the previous entry is stored to be
 * able to traverse the list from back to front. Second, the encoding with an
 * optional string length of the entry itself is stored.
 *
 * The length of the previous entry is encoded in the following way:
 * If this length is smaller than 254 bytes, it will only consume a single
 * byte that takes the length as value. When the length is greater than or
 * equal to 254, it will consume 5 bytes. The first byte is set to 254 to
 * indicate a larger value is following. The remaining 4 bytes take the
 * length of the previous entry as value.
 *
 * The other header field of the entry itself depends on the contents of the
 * entry. When the entry is a string, the first 2 bits of this header will hold
 * the type of encoding used to store the length of the string, followed by the
 * actual length of the string. When the entry is an integer the first 2 bits
 * are both set to 1. The following 2 bits are used to specify what kind of
 * integer will be stored after this header. An overview of the different
 * types and encodings is as follows:
 *
 * |00pppppp| - 1 byte
 *      String value with length less than or equal to 63 bytes (6 bits).
 * |01pppppp|qqqqqqqq| - 2 bytes
 *      String value with length less than or equal to 16383 bytes (14 bits).
 * |10______|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| - 5 bytes
 *      String value with length greater than or equal to 16384 bytes.
 * |1100____| - 1 byte
 *      Integer encoded as int16_t (2 bytes).
 * |1101____| - 1 byte
 *      Integer encoded as int32_t (4 bytes).
 * |1110____| - 1 byte
 *      Integer encoded as int64_t (8 bytes).
 */
#+END_SRC

***** defines
#+BEGIN_SRC C++
#define ZIP_END 255
#define ZIP_BIGLEN 254 // 对于prev length的大长度头字节编码

/* Different encoding/length possibilities */
// 对应字符串的头字节编码
#define ZIP_STR_06B (0 << 6)
#define ZIP_STR_14B (1 << 6)
#define ZIP_STR_32B (2 << 6)
// 对应整数的头字节编码
#define ZIP_INT_16B (0xc0 | 0<<4)
#define ZIP_INT_32B (0xc0 | 1<<4)
#define ZIP_INT_64B (0xc0 | 2<<4)

/* Macro's to determine type */
// 判断这个item是否为string还是int.
#define ZIP_IS_STR(enc) (((enc) & 0xc0) < 0xc0)
#define ZIP_IS_INT(enc) (!ZIP_IS_STR(enc) && ((enc) & 0x30) < 0x30)

/* Utility macros */
// size(uint32_t).包括头部4个字节长度.
#define ZIPLIST_BYTES(zl)       (*((uint32_t*)(zl)))
// tail offset(uint32_t)
#define ZIPLIST_TAIL_OFFSET(zl) (*((uint32_t*)((zl)+sizeof(uint32_t))))
// length(uint16_t)
#define ZIPLIST_LENGTH(zl)      (*((uint16_t*)((zl)+sizeof(uint32_t)*2)))
#define ZIPLIST_HEADER_SIZE     (sizeof(uint32_t)*2+sizeof(uint16_t))
#define ZIPLIST_ENTRY_HEAD(zl)  ((zl)+ZIPLIST_HEADER_SIZE)
#define ZIPLIST_ENTRY_TAIL(zl)  ((zl)+ZIPLIST_TAIL_OFFSET(zl))
#define ZIPLIST_ENTRY_END(zl)   ((zl)+ZIPLIST_BYTES(zl)-1)

/* We know a positive increment can only be 1 because entries can only be
 * pushed one at a time. */
#define ZIPLIST_INCR_LENGTH(zl,incr) { \
    if (ZIPLIST_LENGTH(zl) < UINT16_MAX) ZIPLIST_LENGTH(zl)+=incr; }
#+END_SRC

***** Interface
操作接口还算是比较简洁的，大致都明白每个接口的含义。
#+BEGIN_SRC C++
#define ZIPLIST_HEAD 0
#define ZIPLIST_TAIL 1

unsigned char *ziplistNew(void);
unsigned char *ziplistPush(unsigned char *zl, unsigned char *s, unsigned int slen, int where);
unsigned char *ziplistIndex(unsigned char *zl, int index);
unsigned char *ziplistNext(unsigned char *zl, unsigned char *p);
unsigned char *ziplistPrev(unsigned char *zl, unsigned char *p);
// unsigned char* p应该对应某个item.
unsigned int ziplistGet(unsigned char *p, unsigned char **sval, unsigned int *slen, long long *lval);
unsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen);
unsigned char *ziplistDelete(unsigned char *zl, unsigned char **p);
unsigned char *ziplistDeleteRange(unsigned char *zl, unsigned int index, unsigned int num);
unsigned int ziplistCompare(unsigned char *p, unsigned char *s, unsigned int slen);
unsigned int ziplistLen(unsigned char *zl);
size_t ziplistBlobLen(unsigned char *zl);
#+END_SRC

***** zipEntryEncoding
根据这个entry得到对应的encoding.通过encoding可以知道这个entry的类型以及长度.
#+BEGIN_SRC C++
/* Return the encoding pointer to by 'p'. */
static unsigned int zipEntryEncoding(unsigned char *p) {
    /* String encoding: 2 MSBs */ // 得到最高2位
    unsigned char b = p[0] & 0xc0;
    if (b < 0xc0) {
        return b;
    } else {
        /* Integer encoding: 4 MSBs */
        return p[0] & 0xf0;
    }
    assert(NULL);
    return 0;
}
#+END_SRC

***** zipIntSize
如果encoding是int的话，那么知道这个int占用的字节数.
#+BEGIN_SRC C++
/* Return bytes needed to store integer encoded by 'encoding' */
static unsigned int zipIntSize(unsigned char encoding) {
    switch(encoding) {
    case ZIP_INT_16B: return sizeof(int16_t);
    case ZIP_INT_32B: return sizeof(int32_t);
    case ZIP_INT_64B: return sizeof(int64_t);
    }
    assert(NULL);
    return 0;
}
#+END_SRC

***** zipDecodeLength
根据entry得到value的长度(return value)，同时得到表示这个长度所占用的字节数(lensize).
算法非常直接而且也没有什么绕的地方.
#+BEGIN_SRC C++
/* Decode the encoded length pointed by 'p'. If a pointer to 'lensize' is
 * provided, it is set to the number of bytes required to encode the length. */
static unsigned int zipDecodeLength(unsigned char *p, unsigned int *lensize) {
    unsigned char encoding = zipEntryEncoding(p);
    unsigned int len = 0;

    if (ZIP_IS_STR(encoding)) {
        switch(encoding) {
        case ZIP_STR_06B:
            len = p[0] & 0x3f;
            if (lensize) *lensize = 1;
            break;
        case ZIP_STR_14B:
            len = ((p[0] & 0x3f) << 8) | p[1];
            if (lensize) *lensize = 2;
            break;
        case ZIP_STR_32B:
            len = (p[1] << 24) | (p[2] << 16) | (p[3] << 8) | p[4];
            if (lensize) *lensize = 5;
            break;
        default:
            assert(NULL);
        }
    } else {
        len = zipIntSize(encoding);
        if (lensize) *lensize = 1;
    }
    return len;
}
#+END_SRC

***** zipEncodeLength
根据encoding以及长度rawlen写入内存.判断encoding是否为string/int,然后根据rawlen的范围然后打包.
#+BEGIN_SRC C++
/* Encode the length 'l' writing it in 'p'. If p is NULL it just returns
 * the amount of bytes required to encode such a length. */
static unsigned int zipEncodeLength(unsigned char *p, unsigned char encoding, unsigned int rawlen) {
    unsigned char len = 1, buf[5];

    if (ZIP_IS_STR(encoding)) {
        /* Although encoding is given it may not be set for strings,
         * so we determine it here using the raw length. */
        if (rawlen <= 0x3f) {
            if (!p) return len;
            buf[0] = ZIP_STR_06B | rawlen;
        } else if (rawlen <= 0x3fff) {
            len += 1;
            if (!p) return len;
            buf[0] = ZIP_STR_14B | ((rawlen >> 8) & 0x3f);
            buf[1] = rawlen & 0xff;
        } else {
            len += 4;
            if (!p) return len;
            buf[0] = ZIP_STR_32B;
            buf[1] = (rawlen >> 24) & 0xff;
            buf[2] = (rawlen >> 16) & 0xff;
            buf[3] = (rawlen >> 8) & 0xff;
            buf[4] = rawlen & 0xff;
        }
    } else {
        /* Implies integer encoding, so length is always 1. */
        if (!p) return len;
        buf[0] = encoding;
    }

    /* Store this length at p */
    memcpy(p,buf,len);
    return len;
}
#+END_SRC

***** zipPrevDecodeLength
根据entry得到前面一个entry的长度.首先读取1个字节.返回字节长度(return value)以及占用字节数(lensize)
#+BEGIN_SRC C++
/* Decode the length of the previous element stored at "p". */
static unsigned int zipPrevDecodeLength(unsigned char *p, unsigned int *lensize) {
    unsigned int len = *p;
    if (len < ZIP_BIGLEN) {
        if (lensize) *lensize = 1;
    } else {
        if (lensize) *lensize = 1+sizeof(len);
        memcpy(&len,p+1,sizeof(len));
        memrev32ifbe(&len); // 按照小端存储.
    }
    return len;
}
#+END_SRC

***** zipPrevEncodeLength
encode前面一个entry的长度.返回占用了多少个字节.如果p==NULL的话那么仅仅是计算而不写
#+BEGIN_SRC C++
/* Encode the length of the previous entry and write it to "p". Return the
 * number of bytes needed to encode this length if "p" is NULL. */
static unsigned int zipPrevEncodeLength(unsigned char *p, unsigned int len) {
    if (p == NULL) {
        return (len < ZIP_BIGLEN) ? 1 : sizeof(len)+1;
    } else {
        if (len < ZIP_BIGLEN) {
            p[0] = len;
            return 1;
        } else {
            p[0] = ZIP_BIGLEN;
            memcpy(p+1,&len,sizeof(len));
            memrev32ifbe(p+1); // 按照小端存储.
            return 1+sizeof(len);
        }
    }
}
#+END_SRC

***** zipPrevEncodeLengthForceLarge
强制按照large size方式写入.
#+BEGIN_SRC C++
/* Encode the length of the previous entry and write it to "p". This only
 * uses the larger encoding (required in __ziplistCascadeUpdate). */
static void zipPrevEncodeLengthForceLarge(unsigned char *p, unsigned int len) {
    if (p == NULL) return;
    p[0] = ZIP_BIGLEN;
    memcpy(p+1,&len,sizeof(len));
    memrev32ifbe(p+1);
}
#+END_SRC

***** zipPrevLenByteDiff
如果修改前面一个entry的length的话会造成多少个字节变动.NOTICE(dirlt):这个应该是在修改时候使用的吧.
#+BEGIN_SRC C++
/* Return the difference in number of bytes needed to store the new length
 * "len" on the entry pointed to by "p". */
static int zipPrevLenByteDiff(unsigned char *p, unsigned int len) {
    unsigned int prevlensize;
    zipPrevDecodeLength(p,&prevlensize);
    return zipPrevEncodeLength(NULL,len)-prevlensize;
}
#+END_SRC

***** zipTryEncoding
尝试将内容压缩称为int表示并且返回encoding.如果成功的话返回1否则0.
#+BEGIN_SRC C++
/* Check if string pointed to by 'entry' can be encoded as an integer.
 * Stores the integer value in 'v' and its encoding in 'encoding'. */
static int zipTryEncoding(unsigned char *entry, unsigned int entrylen, long long *v, unsigned char *encoding) {
    long long value;

    if (entrylen >= 32 || entrylen == 0) return 0;
    if (string2ll((char*)entry,entrylen,&value)) {
        /* Great, the string can be encoded. Check what's the smallest
         * of our encoding types that can hold this value. */
        if (value >= INT16_MIN && value <= INT16_MAX) {
            *encoding = ZIP_INT_16B;
        } else if (value >= INT32_MIN && value <= INT32_MAX) {
            *encoding = ZIP_INT_32B;
        } else {
            *encoding = ZIP_INT_64B;
        }
        *v = value;
        return 1;
    }
    return 0;
}
#+END_SRC

***** zipSaveInteger
根据encoding来存储int.内部的话还是按照小端方式来进行存储.
#+BEGIN_SRC C++
/* Store integer 'value' at 'p', encoded as 'encoding' */
static void zipSaveInteger(unsigned char *p, int64_t value, unsigned char encoding) {
    int16_t i16;
    int32_t i32;
    int64_t i64;
    if (encoding == ZIP_INT_16B) {
        i16 = value;
        memcpy(p,&i16,sizeof(i16));
        memrev16ifbe(p);
    } else if (encoding == ZIP_INT_32B) {
        i32 = value;
        memcpy(p,&i32,sizeof(i32));
        memrev32ifbe(p);
    } else if (encoding == ZIP_INT_64B) {
        i64 = value;
        memcpy(p,&i64,sizeof(i64));
        memrev64ifbe(p);
    } else {
        assert(NULL);
    }
}
#+END_SRC

***** zipLoadInteger
根据encoding来载入int.注意这里也做了大小端的转变.
#+BEGIN_SRC C++
/* Read integer encoded as 'encoding' from 'p' */
static int64_t zipLoadInteger(unsigned char *p, unsigned char encoding) {
    int16_t i16;
    int32_t i32;
    int64_t i64, ret = 0;
    if (encoding == ZIP_INT_16B) {
        memcpy(&i16,p,sizeof(i16));
        memrev16ifbe(&i16);
        ret = i16;
    } else if (encoding == ZIP_INT_32B) {
        memcpy(&i32,p,sizeof(i32));
        memrev16ifbe(&i32);
        ret = i32;
    } else if (encoding == ZIP_INT_64B) {
        memcpy(&i64,p,sizeof(i64));
        memrev16ifbe(&i64);
        ret = i64;
    } else {
        assert(NULL);
    }
    return ret;
}
#+END_SRC

***** zipEntry
将entry载入内存生成zlentry结构.
#+BEGIN_SRC C++
/* Return a struct with all information about an entry. */
static zlentry zipEntry(unsigned char *p) {
    zlentry e;
    e.prevrawlen = zipPrevDecodeLength(p,&e.prevrawlensize); // 1.解开前面entry长度
    e.len = zipDecodeLength(p+e.prevrawlensize,&e.lensize); // 2.解开本身长度
    e.headersize = e.prevrawlensize+e.lensize; //3. 计算头部长度
    e.encoding = zipEntryEncoding(p+e.prevrawlensize); // 4.计算encoding.
    e.p = p;
    return e;
}
#+END_SRC

***** zipRawEntryLength
这个entry实际占用的字节数.
#+BEGIN_SRC C++
/* Return the total number of bytes used by the entry at "p". */
static unsigned int zipRawEntryLength(unsigned char *p) {
    zlentry e = zipEntry(p);
    return e.headersize + e.len;
}
#+END_SRC

***** __ziplistCascadeUpdate
这个发生在如果一个块被插入或者是某个块被删除，导致整个大小需要重新计算时候触发的。
这个更新可能是级联的。可以看到实现细节还是比较多的(比较琐碎).另外需要关注的就是什么时候break.
   - 已经达到末尾
   - 长度没有发生变化
   - 长度占用大小表示没有发生变化(或者是缩小了).
#+BEGIN_SRC C++
/* When an entry is inserted, we need to set the prevlen field of the next
 * entry to equal the length of the inserted entry. It can occur that this
 * length cannot be encoded in 1 byte and the next entry needs to be grow
 * a bit larger to hold the 5-byte encoded prevlen. This can be done for free,
 * because this only happens when an entry is already being inserted (which
 * causes a realloc and memmove). However, encoding the prevlen may require
 * that this entry is grown as well. This effect may cascade throughout
 * the ziplist when there are consecutive entries with a size close to
 * ZIP_BIGLEN, so we need to check that the prevlen can be encoded in every
 * consecutive entry.
 *
 * Note that this effect can also happen in reverse, where the bytes required
 * to encode the prevlen field can shrink. This effect is deliberately ignored,
 * because it can cause a "flapping" effect where a chain prevlen fields is
 * first grown and then shrunk again after consecutive inserts. Rather, the
 * field is allowed to stay larger than necessary, because a large prevlen
 * field implies the ziplist is holding large entries anyway.
 *
 * The pointer "p" points to the first entry that does NOT need to be
 * updated, i.e. consecutive fields MAY need an update. */
static unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) {
    size_t curlen = ZIPLIST_BYTES(zl), rawlen, rawlensize;
    size_t offset, noffset, extra;
    unsigned char *np;
    zlentry cur, next;

    while (p[0] != ZIP_END) { // 最后元素
        cur = zipEntry(p);
        rawlen = cur.headersize + cur.len;
        rawlensize = zipPrevEncodeLength(NULL,rawlen);

        /* Abort if there is no next entry. */
        if (p[rawlen] == ZIP_END) break; // 最后元素.
        next = zipEntry(p+rawlen);

        /* Abort when "prevlen" has not changed. */
        if (next.prevrawlen == rawlen) break; // 如果长度没有发生改变.

        if (next.prevrawlensize < rawlensize) { // 如果原长度更小，现在需要扩大.
            /* The "prevlen" field of "next" needs more bytes to hold
             * the raw length of "cur". */
            offset = p-zl;
            extra = rawlensize-next.prevrawlensize;
            zl = ziplistResize(zl,curlen+extra); // 那么需要腾出extra字节.
            p = zl+offset;

            /* Current pointer and offset for next element. */
            np = p+rawlen;
            noffset = np-zl;

            /* Update tail offset when next element is not the tail element. */
            if ((zl+ZIPLIST_TAIL_OFFSET(zl)) != np)
                ZIPLIST_TAIL_OFFSET(zl) += extra;

            /* Move the tail to the back. */
            memmove(np+rawlensize, // 同时移动内存.
                np+next.prevrawlensize,
                curlen-noffset-next.prevrawlensize-1);
            zipPrevEncodeLength(np,rawlen);

            /* Advance the cursor */
            p += rawlen;
            curlen += extra;
        } else {
            if (next.prevrawlensize > rawlensize) { // 如果原长度占用字节更少
                // 那么完全可以通过修改表示达到.
                /* This would result in shrinking, which we want to avoid.
                 * So, set "rawlen" in the available bytes. */
                zipPrevEncodeLengthForceLarge(p+rawlen,rawlen);
            } else {
                zipPrevEncodeLength(p+rawlen,rawlen); // 否则仅仅修改内容.
            }

            /* Stop here, as the raw length of "next" has not changed. */
            break;
        }
    }
    return zl;
}
#+END_SRC

***** __ziplistDelete
删除从某个entry开始的num个.没有仔细地看(应该比较繁琐).直接修改头部一些信息并且memmove一下，
然后调用cascadeupdate来进行每个item的更新.
#+BEGIN_SRC C++
/* Delete "num" entries, starting at "p". Returns pointer to the ziplist. */
static unsigned char *__ziplistDelete(unsigned char *zl, unsigned char *p, unsigned int num) {
    unsigned int i, totlen, deleted = 0;
    size_t offset;
    int nextdiff = 0;
    zlentry first, tail;

    first = zipEntry(p);
    for (i = 0; p[0] != ZIP_END && i < num; i++) {
        p += zipRawEntryLength(p);
        deleted++;
    }

    totlen = p-first.p;
    if (totlen > 0) {
        if (p[0] != ZIP_END) {
            /* Tricky: storing the prevlen in this entry might reduce or
             * increase the number of bytes needed, compared to the current
             * prevlen. Note that we can always store this length because
             * it was previously stored by an entry that is being deleted. */
            nextdiff = zipPrevLenByteDiff(p,first.prevrawlen);
            zipPrevEncodeLength(p-nextdiff,first.prevrawlen);

            /* Update offset for tail */
            ZIPLIST_TAIL_OFFSET(zl) -= totlen;

            /* When the tail contains more than one entry, we need to take
             * "nextdiff" in account as well. Otherwise, a change in the
             * size of prevlen doesn't have an effect on the *tail* offset. */
            tail = zipEntry(p);
            if (p[tail.headersize+tail.len] != ZIP_END)
                ZIPLIST_TAIL_OFFSET(zl) += nextdiff;

            /* Move tail to the front of the ziplist */
            memmove(first.p,p-nextdiff,ZIPLIST_BYTES(zl)-(p-zl)-1+nextdiff);
        } else {
            /* The entire tail was deleted. No need to move memory. */
            ZIPLIST_TAIL_OFFSET(zl) = (first.p-zl)-first.prevrawlen;
        }

        /* Resize and update length */
        offset = first.p-zl;
        zl = ziplistResize(zl, ZIPLIST_BYTES(zl)-totlen+nextdiff);
        ZIPLIST_INCR_LENGTH(zl,-deleted);
        p = zl+offset;

        /* When nextdiff != 0, the raw length of the next entry has changed, so
         * we need to cascade the update throughout the ziplist */
        if (nextdiff != 0)
            zl = __ziplistCascadeUpdate(zl,p);
    }
    return zl;
}
#+END_SRC

***** __ziplistInsert
在某个点之前插入.实现起来也是比较繁琐的没有细看.TODO(dirlt):仔细看看实现.应该是比较繁琐的.想必作者也花了不少时间.
#+BEGIN_SRC C++
/* Insert item at "p". */
static unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) {
    size_t curlen = ZIPLIST_BYTES(zl), reqlen, prevlen = 0;
    size_t offset;
    int nextdiff = 0;
    unsigned char encoding = 0;
    long long value = 123456789; /* initialized to avoid warning. Using a value
                                    that is easy to see if for some reason
                                    we use it uninitialized. */
    zlentry entry, tail;

    /* Find out prevlen for the entry that is inserted. */
    if (p[0] != ZIP_END) {
        entry = zipEntry(p);
        prevlen = entry.prevrawlen;
    } else {
        unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl);
        if (ptail[0] != ZIP_END) {
            prevlen = zipRawEntryLength(ptail);
        }
    }

    /* See if the entry can be encoded */
    if (zipTryEncoding(s,slen,&value,&encoding)) {
        /* 'encoding' is set to the appropriate integer encoding */
        reqlen = zipIntSize(encoding);
    } else {
        /* 'encoding' is untouched, however zipEncodeLength will use the
         * string length to figure out how to encode it. */
        reqlen = slen;
    }
    /* We need space for both the length of the previous entry and
     * the length of the payload. */
    reqlen += zipPrevEncodeLength(NULL,prevlen);
    reqlen += zipEncodeLength(NULL,encoding,slen);

    /* When the insert position is not equal to the tail, we need to
     * make sure that the next entry can hold this entry's length in
     * its prevlen field. */
    nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;

    /* Store offset because a realloc may change the address of zl. */
    offset = p-zl;
    zl = ziplistResize(zl,curlen+reqlen+nextdiff);
    p = zl+offset;

    /* Apply memory move when necessary and update tail offset. */
    if (p[0] != ZIP_END) {
        /* Subtract one because of the ZIP_END bytes */
        memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);

        /* Encode this entry's raw length in the next entry. */
        zipPrevEncodeLength(p+reqlen,reqlen);

        /* Update offset for tail */
        ZIPLIST_TAIL_OFFSET(zl) += reqlen;

        /* When the tail contains more than one entry, we need to take
         * "nextdiff" in account as well. Otherwise, a change in the
         * size of prevlen doesn't have an effect on the *tail* offset. */
        tail = zipEntry(p+reqlen);
        if (p[reqlen+tail.headersize+tail.len] != ZIP_END)
            ZIPLIST_TAIL_OFFSET(zl) += nextdiff;
    } else {
        /* This element will be the new tail. */
        ZIPLIST_TAIL_OFFSET(zl) = p-zl;
    }

    /* When nextdiff != 0, the raw length of the next entry has changed, so
     * we need to cascade the update throughout the ziplist */
    if (nextdiff != 0) {
        offset = p-zl;
        zl = __ziplistCascadeUpdate(zl,p+reqlen);
        p = zl+offset;
    }

    /* Write the entry */
    p += zipPrevEncodeLength(p,prevlen);
    p += zipEncodeLength(p,encoding,slen);
    if (ZIP_IS_STR(encoding)) {
        memcpy(p,s,slen);
    } else {
        zipSaveInteger(p,value,encoding);
    }
    ZIPLIST_INCR_LENGTH(zl,1);
    return zl;
}
#+END_SRC

***** zipListNew
TODO(dirlt):

***** zipListResize
TODO(dirlt):

***** ziplistPush
TODO(dirlt):

***** ziplistIndex
TODO(dirlt):

***** ziplistNext
TODO(dirlt):

***** ziplistPrev
TODO(dirlt):

***** ziplistGet
TODO(dirlt):

***** ziplistInsert
TODO(dirlt):

***** ziplistDelete
TODO(dirlt):

***** ziplistDeleteRange
TODO(dirlt):

***** ziplistCompare
TODO(dirlt):

***** ziplistLen
TODO(dirlt):

***** ziplistBlobLen
TODO(dirlt):

***** ziplistRepr
TODO(dirlt):

**** zipmap
zipmap是一种内存非常紧凑分配的string->string的map.操作上都是字符串类型.
从注释上面可以看到O(n)的lookup时间复杂度，并且当item个数超过某个数值之后就会构建稀疏hashtable.
可以见到在元素个数非常少的情况下面是在节省内存和查找速度上面是一个折衷。
#+BEGIN_SRC C++
/* String -> String Map data structure optimized for size.
 * This file implements a data structure mapping strings to other strings
 * implementing an O(n) lookup data structure designed to be very memory
 * efficient.
 *
 * The Redis Hash type uses this data structure for hashes composed of a small
 * number of elements, to switch to an hash table once a given number of
 * elements is reached.
 *
 * Given that many times Redis Hashes are used to represent objects composed
 * of few fields, this is a very big win in terms of used memory.
 *
*/
#+END_SRC

***** Format
注释开头有关于zipmap内部实现.还是比较好懂的。对于value部分的实际长度应该是<len>-<free>.
相对于ziplist实现来说zipmap还是更加简单一些。这里注意zmlen是entries的数目而不是大小
这个可以通过阅读zipmapLen和zipmapBlobLen就可以发现。

#+BEGIN_SRC C++
/* Memory layout of a zipmap, for the map "foo" => "bar", "hello" => "world":
 *
 * <zmlen><len>"foo"<len><free>"bar"<len>"hello"<len><free>"world"
 *
 * <zmlen> is 1 byte length that holds the current size of the zipmap.
 * When the zipmap length is greater than or equal to 254, this value
 * is not used and the zipmap needs to be traversed to find out the length.
 *
 * <len> is the length of the following string (key or value).
 * <len> lengths are encoded in a single value or in a 5 bytes value.
 * If the first byte value (as an unsigned 8 bit value) is between 0 and
 * 252, it's a single-byte length. If it is 253 then a four bytes unsigned
 * integer follows (in the host byte ordering). A value fo 255 is used to
 * signal the end of the hash. The special value 254 is used to mark
 * empty space that can be used to add new key/value pairs.
 *
 * <free> is the number of free unused bytes
 * after the string, resulting from modification of values associated to a
 * key (for instance if "foo" is set to "bar', and later "foo" will be se to
 * "hi", I'll have a free byte to use if the value will enlarge again later,
 * or even in order to add a key/value pair if it fits.
 *
 * <free> is always an unsigned 8 bit number, because if after an
 * update operation there are more than a few free bytes, the zipmap will be
 * reallocated to make sure it is as small as possible.
 *
 * The most compact representation of the above two elements hash is actually:
 *
 * "\x02\x03foo\x03\x00bar\x05hello\x05\x00world\xff"
 *
 * Note that because keys and values are prefixed length "objects",
 * the lookup will take O(N) where N is the number of elements
 * in the zipmap and *not* the number of bytes needed to represent the zipmap.
 * This lowers the constant times considerably.
 */
#+END_SRC

***** Interface
我们来看看zipmap提供的接口。粗略的看一下似乎基本上就是hashtable提供的接口(甚至相对于hashtable来说更加简单).
#+BEGIN_SRC C++
#define ZIPMAP_BIGLEN 254
#define ZIPMAP_END 255

/* The following defines the max value for the <free> field described in the
 * comments above, that is, the max number of trailing bytes in a value. */
#define ZIPMAP_VALUE_MAX_FREE 4

/* The following macro returns the number of bytes needed to encode the length
 * for the integer value _l, that is, 1 byte for lengths < ZIPMAP_BIGLEN and
 * 5 bytes for all the other lengths. */
#define ZIPMAP_LEN_BYTES(_l) (((_l) < ZIPMAP_BIGLEN) ? 1 : sizeof(unsigned int)+1)

unsigned char *zipmapNew(void);
unsigned char *zipmapSet(unsigned char *zm, unsigned char *key, unsigned int klen, unsigned char *val, unsigned int vlen, int *update);
unsigned char *zipmapDel(unsigned char *zm, unsigned char *key, unsigned int klen, int *deleted);
unsigned char *zipmapRewind(unsigned char *zm);
unsigned char *zipmapNext(unsigned char *zm, unsigned char **key, unsigned int *klen, unsigned char **value, unsigned int *vlen);
int zipmapGet(unsigned char *zm, unsigned char *key, unsigned int klen, unsigned char **value, unsigned int *vlen);
int zipmapExists(unsigned char *zm, unsigned char *key, unsigned int klen);
unsigned int zipmapLen(unsigned char *zm);
size_t zipmapBlobLen(unsigned char *zm);
void zipmapRepr(unsigned char *p);
#+END_SRC

***** zipmapNew
TODO(dirlt):

***** zipmapDecodeLength
从k/v开头得到分配的字节数目.
#+BEGIN_SRC C++
/* Decode the encoded length pointed by 'p' */
static unsigned int zipmapDecodeLength(unsigned char *p) {
    unsigned int len = *p;

    if (len < ZIPMAP_BIGLEN) return len;
    memcpy(&len,p+1,sizeof(unsigned int));
    memrev32ifbe(&len);
    return len;
}
#+END_SRC

***** zipmapEncodeLength
将len字节数目写入zipmap.
#+BEGIN_SRC C++
/* Encode the length 'l' writing it in 'p'. If p is NULL it just returns
 * the amount of bytes required to encode such a length. */
static unsigned int zipmapEncodeLength(unsigned char *p, unsigned int len) {
    if (p == NULL) {
        return ZIPMAP_LEN_BYTES(len);
    } else {
        if (len < ZIPMAP_BIGLEN) {
            p[0] = len;
            return 1;
        } else {
            p[0] = ZIPMAP_BIGLEN;
            memcpy(p+1,&len,sizeof(len));
            memrev32ifbe(p+1);
            return 1+sizeof(len);
        }
    }
}
#+END_SRC

***** zipmapLookupRaw
通过某个key查找到对应的entry.如果设置了totlen的话那么无论如何都会遍历完成得到大小.
如果匹配上的话那么返回查找到的entry,否则返回NULL.NOTICE(dirlt):逻辑还是比较诡异的.

#+BEGIN_SRC C++
/* Search for a matching key, returning a pointer to the entry inside the
 * zipmap. Returns NULL if the key is not found.
 *
 * If NULL is returned, and totlen is not NULL, it is set to the entire
 * size of the zimap, so that the calling function will be able to
 * reallocate the original zipmap to make room for more entries. */
static unsigned char *zipmapLookupRaw(unsigned char *zm, unsigned char *key, unsigned int klen, unsigned int *totlen) {
    // 注意这里我们从zm+1开始进行遍历.
    unsigned char *p = zm+1, *k = NULL;
    unsigned int l,llen;

    while(*p != ZIPMAP_END) {
        unsigned char free;

        /* Match or skip the key */
        l = zipmapDecodeLength(p);
        llen = zipmapEncodeLength(NULL,l);
        if (key != NULL && k == NULL && l == klen && !memcmp(p+llen,key,l)) { // 如果已经匹配上的话那么没有必要匹配
            /* Only return when the user doesn't care
             * for the total length of the zipmap. */
            if (totlen != NULL) {
                k = p; // 如果需要统计长度的话那么继续统计.
            } else {
                return p;
            }
        }
        p += llen+l;
        /* Skip the value as well */
        l = zipmapDecodeLength(p);
        p += zipmapEncodeLength(NULL,l);
        free = p[0];
        p += l+1+free; /* +1 to skip the free byte */
    }
    if (totlen != NULL) *totlen = (unsigned int)(p-zm)+1;
    return k;
}
#+END_SRC

***** zipmapRequiredLength
对于分配这个kv的话需要分配多少内存.这个3还是比较诡异的，其实必要字段如果free是0的话，
那么只是需要klen+vlen+1即可的.相当于多分配了2个字节吧:).
#+BEGIN_SRC C++
static unsigned long zipmapRequiredLength(unsigned int klen, unsigned int vlen) {
    unsigned int l;

    l = klen+vlen+3; // #define ZIPMAP_VALUE_MAX_FREE 4.
    if (klen >= ZIPMAP_BIGLEN) l += 4; // 这里对于超过BIGLEN的话那么需要+=4.
    if (vlen >= ZIPMAP_BIGLEN) l += 4;
    return l;
}
#+END_SRC

***** zipmapRawKeyLength
key占用的字节数.
#+BEGIN_SRC C++
/* Return the total amount used by a key (encoded length + payload) */
static unsigned int zipmapRawKeyLength(unsigned char *p) {
    unsigned int l = zipmapDecodeLength(p);
    return zipmapEncodeLength(NULL,l) + l;
}
#+END_SRC

***** zipmapRawValueLength
value占用的字节数.注意这里需要考虑1 byte的<free>字节.以及<free>字节表示的内容.
#+BEGIN_SRC C++
/* Return the total amount used by a value
 * (encoded length + single byte free count + payload) */
static unsigned int zipmapRawValueLength(unsigned char *p) {
    unsigned int l = zipmapDecodeLength(p);
    unsigned int used;

    used = zipmapEncodeLength(NULL,l);
    used += p[used] + 1 + l;
    return used;
}
#+END_SRC

***** zipmapRawEntryLength
得到整个entry的长度.得到key长度，越过key然后得到value长度.
#+BEGIN_SRC C++
/* If 'p' points to a key, this function returns the total amount of
 * bytes used to store this entry (entry = key + associated value + trailing
 * free space if any). */
static unsigned int zipmapRawEntryLength(unsigned char *p) {
    unsigned int l = zipmapRawKeyLength(p);
    return l + zipmapRawValueLength(p+l);
}
#+END_SRC

***** zipmapResize
resize还包括了zipmap的delete之后的内存紧缩问题.
#+BEGIN_SRC C++
static inline unsigned char *zipmapResize(unsigned char *zm, unsigned int len) {
    zm = zrealloc(zm, len);
    zm[len-1] = ZIPMAP_END;
    return zm;
}
#+END_SRC

***** zipmapSet
先来看看Set这个接口吧.如果不存在的话那么直接在末尾添加，否则会在远处进行修改(判断free部分是否可以容纳).
#+BEGIN_SRC C++
/* Set key to value, creating the key if it does not already exist.
 * If 'update' is not NULL, *update is set to 1 if the key was
 * already preset, otherwise to 0. */
unsigned char *zipmapSet(unsigned char *zm, unsigned char *key, unsigned int klen, unsigned char *val, unsigned int vlen, int *update) {
    unsigned int zmlen, offset;
    unsigned int freelen, reqlen = zipmapRequiredLength(klen,vlen);
    unsigned int empty, vempty;
    unsigned char *p;

    freelen = reqlen;
    if (update) *update = 0;
    p = zipmapLookupRaw(zm,key,klen,&zmlen);
    if (p == NULL) {
        /* Key not found: enlarge */
        zm = zipmapResize(zm, zmlen+reqlen); // 在最末位添加.
        p = zm+zmlen-1;
        zmlen = zmlen+reqlen;

        /* Increase zipmap length (this is an insert) */
        if (zm[0] < ZIPMAP_BIGLEN) zm[0]++; // 需要修改entries个数.
    } else {
        /* Key found. Is there enough space for the new value? */
        /* Compute the total length: */
        if (update) *update = 1;
        freelen = zipmapRawEntryLength(p);
        if (freelen < reqlen) { // 如果空闲长度不够的话那么需要resize并且memmove.
            /* Store the offset of this key within the current zipmap, so
             * it can be resized. Then, move the tail backwards so this
             * pair fits at the current position. */
            offset = p-zm;
            zm = zipmapResize(zm, zmlen-freelen+reqlen);
            p = zm+offset;

            /* The +1 in the number of bytes to be moved is caused by the
             * end-of-zipmap byte. Note: the *original* zmlen is used. */
            memmove(p+reqlen, p+freelen, zmlen-(offset+freelen+1));
            zmlen = zmlen-freelen+reqlen;
            freelen = reqlen;
        }
    }

    // 然后判断剩余下来的空闲是否超过MAX_FREE.如果超过的话那么需要进行紧缩.
    /* We now have a suitable block where the key/value entry can
     * be written. If there is too much free space, move the tail
     * of the zipmap a few bytes to the front and shrink the zipmap,
     * as we want zipmaps to be very space efficient. */
    empty = freelen-reqlen;
    if (empty >= ZIPMAP_VALUE_MAX_FREE) {
        /* First, move the tail <empty> bytes to the front, then resize
         * the zipmap to be <empty> bytes smaller. */
        offset = p-zm;
        memmove(p+reqlen, p+freelen, zmlen-(offset+freelen+1));
        zmlen -= empty;
        zm = zipmapResize(zm, zmlen);
        p = zm+offset;
        vempty = 0;
    } else {
        vempty = empty;
    }

    // 完成之后然后重新构造kv上面的内容.
    /* Just write the key + value and we are done. */
    /* Key: */
    p += zipmapEncodeLength(p,klen);
    memcpy(p,key,klen);
    p += klen;
    /* Value: */
    p += zipmapEncodeLength(p,vlen);
    *p++ = vempty;
    memcpy(p,val,vlen);
    return zm;
}
#+END_SRC

***** zipmapDel
然后在来看看Delete这个接口.对于delete来说相对于set更加简单直接进行memmove然后resize即可.
#+BEGIN_SRC C++
/* Remove the specified key. If 'deleted' is not NULL the pointed integer is
 * set to 0 if the key was not found, to 1 if it was found and deleted. */
unsigned char *zipmapDel(unsigned char *zm, unsigned char *key, unsigned int klen, int *deleted) {
    unsigned int zmlen, freelen;
    unsigned char *p = zipmapLookupRaw(zm,key,klen,&zmlen);
    if (p) {
        freelen = zipmapRawEntryLength(p);
        memmove(p, p+freelen, zmlen-((p-zm)+freelen+1));
        zm = zipmapResize(zm, zmlen-freelen);

        /* Decrease zipmap length */
        if (zm[0] < ZIPMAP_BIGLEN) zm[0]--;

        if (deleted) *deleted = 1;
    } else {
        if (deleted) *deleted = 0;
    }
    return zm;
}
#+END_SRC

***** zipmapRewind
TODO(dirlt):

***** zipmapNext
TODO(dirlt):

***** zipmapGet
TODO(dirlt):

***** zipmapExists
TODO(dirlt):

***** zipmapLen
TODO(dirlt):

***** zipmapBlobLen
TODO(dirlt):

***** zipmapRepr
TODO(dirlt):

*** Utility
**** version.h
版本号信息

**** sha1.h
sha1算法.里面一个比较有意思的函数就是
#+BEGIN_SRC C++
typedef struct {
    u_int32_t state[5];
    u_int32_t count[2];
    unsigned char buffer[64];
} SHA1_CTX;

void SHA1Transform(u_int32_t state[5], const unsigned char buffer[64]);
#+END_SRC
应该是根据原来的state每次针对64 bytes buffer进行update.应该是SHA1算法核心.

**** fmacros.h
#+BEGIN_SRC C++
#ifndef _REDIS_FMACRO_H
#define _REDIS_FMACRO_H

#define _BSD_SOURCE

#if defined(__linux__) || defined(__OpenBSD__)
#define _XOPEN_SOURCE 700
#else
#define _XOPEN_SOURCE
#endif

// 支持大文件选项.
#define _LARGEFILE_SOURCE
#define _FILE_OFFSET_BITS 64

#endif
#+END_SRC

**** help.h
帮助信息.可以看看help是怎么组织内容的.
#+BEGIN_SRC C++
// 命令分组.
static char *commandGroups[] = {
    "generic",
    "string",
    "list",
    "set",
    "sorted_set",
    "hash",
    "pubsub",
    "transactions",
    "connection",
    "server"
};

// 每条命令.
struct commandHelp {
  char *name; // 名字
  char *params; // 参数
  char *summary; // 概要
  int group; // 所属分组
  char *since; // 从哪个版本引入
} commandHelp[];
#+END_SRC

**** endian.h
统一处理大小端问题.redis认为标准应该是小端表示.
#+BEGIN_SRC C++
#ifndef __ENDIAN_H
#define __ENDIAN_H

void memrev16(void *p);
void memrev32(void *p);
void memrev64(void *p);

/* variants of the function doing the actual convertion only if the target
 * host is big endian */
// 使用下面这些函数实现.
// 名字含义应该是memory reverse 16 if big endian.
#if (BYTE_ORDER == LITTLE_ENDIAN)
#define memrev16ifbe(p)
#define memrev32ifbe(p)
#define memrev64ifbe(p)
#else
#define memrev16ifbe(p) memrev16(p)
#define memrev32ifbe(p) memrev32(p)
#define memrev64ifbe(p) memrev64(p)
#endif

#endif
#+END_SRC

底层实现非常简单，以memrev64表示的话.
#+BEGIN_SRC C++
/* Toggle the 64 bit unsigned integer pointed by *p from little endian to
 * big endian */
void memrev64(void *p) {
    unsigned char *x = p, t;

    t = x[0];
    x[0] = x[7];
    x[7] = t;
    t = x[1];
    x[1] = x[6];
    x[6] = t;
    t = x[2];
    x[2] = x[5];
    x[5] = t;
    t = x[3];
    x[3] = x[4];
    x[4] = t;
}
#+END_SRC

**** util.h
#+BEGIN_SRC C++
// p是pattern.nocase不考虑大小写问题.进行正则匹配.(注意是match而不是search).
int stringmatchlen(const char *p, int plen, const char *s, int slen, int nocase);
int stringmatch(const char *p, const char *s, int nocase);
// 将memory的表示方法转换称为大小.标准应该是字节.
long long memtoll(const char *p, int *err);
// 字符串到数值的转换.
int ll2string(char *s, size_t len, long long value);
int string2ll(char *s, size_t slen, long long *value);
int string2l(char *s, size_t slen, long *value);
int d2string(char *buf, size_t len, double value);
// unix time in microseconds.
long long ustime(void);
#+END_SRC
大概看了里面的实现考虑的情况比较多.不过考虑到接口本身语义很简单所以实现暂时不分析.TODO(dirlt):分析实现.

**** pqsort.h
partial quick sort.功能是针对连续内存里面某段内存[lrange,rrange]进行排序.
#+BEGIN_SRC C++
void
pqsort(void *a, size_t n, size_t es,
    int (*cmp) (const void *, const void *), size_t lrange, size_t rrange);
#+END_SRC
   - a 起始内存地址
   - n 总共多少个元素
   - es 每个单元的大小
   - cmp 比较函数
   - lrange 左边的index
   - rrange 右边的index
TODO(dirlt):可以好好看看实现.

**** config.c
TODO(dirlt):

**** lzf.h
lzf是一个高效的压缩解压算法,后面会单独进行分析.我们这里主要看看文件组织和接口
   - lzf.h 接口文件
   - lzfP.h 考虑lzf可移植性文件
   - lzf_c.c compress实现文件
   - lzf_d.c decompress实现文件
#+BEGIN_SRC C++
unsigned int
lzf_compress (const void *const in_data,  unsigned int in_len,
              void             *out_data, unsigned int out_len);
unsigned int
lzf_decompress (const void *const in_data,  unsigned int in_len,
                void             *out_data, unsigned int out_len);
#+END_SRC
相对于 [[file:./Snappy.org][snappy]] 压缩算法接口更加简洁.

**** sds.h
safe dynamic string.封装的字符串结构.在结构上面封装了很多对应的函数.

***** defines
#+BEGIN_SRC C++
#define SDS_MAX_PREALLOC (1024*1024) // 在sdsMakeRoomFor里面使用

#include <sys/types.h>
#include <stdarg.h>

typedef char *sds;

struct sdshdr { // sds header.
    int len; // 实际长度.
    int free; // 剩余长度
    char buf[]; // 实际返回的sds.注意字符串以\0结尾.
};
#+END_SRC

***** Interface
提供的函数大多数都非常简单，所以这里我们只是稍微看看。后面的话会针对某些比较有意思的接口看看实现。
#+BEGIN_SRC C++
static inline size_t sdslen(const sds s) {
    struct sdshdr *sh = (void*)(s-(sizeof(struct sdshdr)));
    return sh->len;
}

static inline size_t sdsavail(const sds s) {
    struct sdshdr *sh = (void*)(s-(sizeof(struct sdshdr)));
    return sh->free;
}

sds sdsnewlen(const void *init, size_t initlen); // ctor
sds sdsnew(const char *init);  // ctor
sds sdsempty(); // make empty
size_t sdslen(const sds s);
sds sdsdup(const sds s); // duplicate
void sdsfree(sds s);
size_t sdsavail(sds s);
sds sdsgrowzero(sds s, size_t len); // grow to len.
sds sdscatlen(sds s, void *t, size_t len); // append.
sds sdscat(sds s, char *t);
sds sdscatsds(sds s, sds t);
sds sdscpylen(sds s, char *t, size_t len);
sds sdscpy(sds s, char *t);

sds sdscatvprintf(sds s, const char *fmt, va_list ap);
#ifdef __GNUC__
sds sdscatprintf(sds s, const char *fmt, ...)
    __attribute__((format(printf, 2, 3)));
#else
sds sdscatprintf(sds s, const char *fmt, ...);
#endif

sds sdstrim(sds s, const char *cset); // 开头和结尾去掉cset里面的字符并且返回.
sds sdsrange(sds s, int start, int end); // [start,end)
void sdsupdatelen(sds s);
void sdsclear(sds s);
int sdscmp(sds s1, sds s2);
sds *sdssplitlen(char *s, int len, char *sep, int seplen, int *count); // 拆分s称为多个sds对象.
void sdsfreesplitres(sds *tokens, int count); // 释放多个sds对象.
void sdstolower(sds s);
void sdstoupper(sds s);
sds sdsfromlonglong(long long value);
sds sdscatrepr(sds s, char *p, size_t len); // sds打印出来.
sds *sdssplitargs(char *line, int *argc); // 拆分line称为多个sds对象
#+END_SRC

***** Implementation
TODO(dirlt):

*** Virtual Memory
redis实现了自己的虚拟内存.但是我不确定这些虚拟内存具体实现了哪些功能.
**** defines
#+BEGIN_SRC C++
// redis.h
/* Virtual memory object->where field. */
#define REDIS_VM_MEMORY 0       /* The object is on memory */
#define REDIS_VM_SWAPPED 1      /* The object is on disk */
#define REDIS_VM_SWAPPING 2     /* Redis is swapping this object on disk */
#define REDIS_VM_LOADING 3      /* Redis is loading this object from disk */

/* Virtual memory static configuration stuff.
 * Check vmFindContiguousPages() to know more about this magic numbers. */
#define REDIS_VM_MAX_NEAR_PAGES 65536
#define REDIS_VM_MAX_RANDOM_JUMP 4096
#define REDIS_VM_MAX_THREADS 32
#define REDIS_THREAD_STACK_SIZE (1024*1024*4)
/* The following is the *percentage* of completed I/O jobs to process when the
 * handelr is called. While Virtual Memory I/O operations are performed by
 * threads, this operations must be processed by the main thread when completed
 * in order to take effect. */
#define REDIS_MAX_COMPLETED_JOBS_PROCESSED 1

/* The VM pointer structure - identifies an object in the swap file.
 *
 * This object is stored in place of the value
 * object in the main key->value hash table representing a database.
 * Note that the first fields (type, storage) are the same as the redisObject
 * structure so that vmPointer strucuters can be accessed even when casted
 * as redisObject structures.
 *
 * This is useful as we don't know if a value object is or not on disk, but we
 * are always able to read obj->storage to check this. For vmPointer
 * structures "type" is set to REDIS_VMPOINTER (even if without this field
 * is still possible to check the kind of object from the value of 'storage').*/
// 头部几个字节可以直接转换称为redisObject.就可以了解这个对象是在disk还是memory上.
typedef struct vmPointer {
    unsigned type:4;
    unsigned storage:2; /* REDIS_VM_SWAPPED or REDIS_VM_LOADING */
    unsigned notused:26;
    unsigned int vtype; /* type of the object stored in the swap file */
    off_t page;         /* the page at witch the object is stored on disk */
    off_t usedpages;    /* number of pages used on disk */
} vmpointer;
#+END_SRC

**** Interface
下面是vm提供的接口，看上去还是比较繁杂的，还是需要一个个函数仔细分析。
#+BEGIN_SRC C++
/* Virtual Memory */
void vmInit(void);
void vmMarkPagesFree(off_t page, off_t count);
robj *vmLoadObject(robj *o);
robj *vmPreviewObject(robj *o);
int vmSwapOneObjectBlocking(void);
int vmSwapOneObjectThreaded(void);
int vmCanSwapOut(void);
void vmThreadedIOCompletedJob(aeEventLoop *el, int fd, void *privdata, int mask);
void vmCancelThreadedIOJob(robj *o);
void lockThreadedIO(void);
void unlockThreadedIO(void);
int vmSwapObjectThreaded(robj *key, robj *val, redisDb *db);
void freeIOJob(iojob *j);
void queueIOJob(iojob *j);
int vmWriteObjectOnSwap(robj *o, off_t page);
robj *vmReadObjectFromSwap(off_t page, int type);
void waitEmptyIOJobsQueue(void);
void vmReopenSwapFile(void);
int vmFreePage(off_t page);
void zunionInterBlockClientOnSwappedKeys(redisClient *c, struct redisCommand *cmd, int argc, robj **argv);
void execBlockClientOnSwappedKeys(redisClient *c, struct redisCommand *cmd, int argc, robj **argv);
int blockClientOnSwappedKeys(redisClient *c);
int dontWaitForSwappedKey(redisClient *c, robj *key);
void handleClientsBlockedOnSwappedKey(redisDb *db, robj *key);
vmpointer *vmSwapObjectBlocking(robj *val);
#+END_SRC

